{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTa4Q_raXC5z"
      },
      "source": [
        "# Stock Market News Sentiment\n",
        "This project looks into classifying the sentiment of stock market news and tweets into a bullish, bearish, or neutral outlook. \n",
        "\n",
        "The data is a concatenation from [Kaggle: Stock-Market Sentiment Dataset](https://www.kaggle.com/datasets/yash612/stockmarket-sentiment-dataset) and [Kaggle: Financial Sentiment Analysis](https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis). The data was combined in [data_extraction.ipynb](data_extraction.ipynb)\n",
        "\n",
        "The data is broken up into two columns: `Text` that is a block of text and `Sentiment` that is a value between -1 and 1 value, meaning -1 is negative sentiment, 0 is neutral, and 1 is positive sentiment.\n",
        "\n",
        "A model such as this can be applied to many areas outside of finance such as marketing, politics, or product feedback. It could also be combined with other algorithms to create a multi-modal approach for a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9IBlY5UXC50"
      },
      "source": [
        "# Set up\n",
        "Import the necessary dependencies and load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9YpRSl-GXM-U",
        "outputId": "fc8500f5-4a78-46b7-e68f-e0b8b8db4b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.10/dist-packages (2.11.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install pyprind\n",
        "!pip install tensorflow\n",
        "!pip install keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lI9ltICoXC50"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "import pyprind\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import RNN, Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NazWEKZWXC51"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLJXCYmZXC51"
      },
      "source": [
        "# EDA & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLkvBp5DXC51"
      },
      "source": [
        "## EDA\n",
        "After exploring the data, here are some key findings that will help in our preprocessing and feature extraction:\n",
        "- There are 16479 records, with 11842 being unique.\n",
        "- The max words are 81 while the minimum words are 2. The average amount of words are just over 19.\n",
        "- The sentiment count for each value is '1' at 6900, '0' at 6009, and '-1' at 3570, which makes me believe that the model might have some skew away from negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ean9OE4SXC52",
        "outputId": "d7130c07-bb78-40e2-f49b-588f0f69305c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 16479,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11842,\n        \"samples\": [\n          \"ALEXANDRIA , Va. , June 7 -- Michael G. Williams of Newbury Park , Calif. , has developed a network device .\",\n          \"When is Demark coming back to prop up AAP?  Yesterday a classic dead cat bounce.   Now a value stock, need go lower to find size buyers.\",\n          \"AXTI eleased news. Watching if this can go into 3s today  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-31430e5e-15a2-475f-85f7-97f6101159ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MNTA Over 12.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OI  Over 21.37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31430e5e-15a2-475f-85f7-97f6101159ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31430e5e-15a2-475f-85f7-97f6101159ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31430e5e-15a2-475f-85f7-97f6101159ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f00c680a-1463-4bd1-abde-e28d61641b13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f00c680a-1463-4bd1-abde-e28d61641b13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f00c680a-1463-4bd1-abde-e28d61641b13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                Text  Sentiment\n",
              "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
              "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
              "2  user I'd be afraid to short AMZN - they are lo...          1\n",
              "3                                  MNTA Over 12.00            1\n",
              "4                                   OI  Over 21.37            1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3JVWBwmXC52",
        "outputId": "2377bb7e-b3c3-44f2-9abf-b5da3eff5621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16479 entries, 0 to 16478\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Text       16479 non-null  object\n",
            " 1   Sentiment  16479 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 257.6+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "J2HnbDhoXC52",
        "outputId": "0b713edd-9df3-4afd-dd5a-64b528730a1c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5826.1067022254565,\n        \"min\": -1.0,\n        \"max\": 16479.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          16479.0,\n          0.2020753686510104,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7d890748-4e3b-4d17-9ab7-351e451beffd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16479.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.202075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.771074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d890748-4e3b-4d17-9ab7-351e451beffd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d890748-4e3b-4d17-9ab7-351e451beffd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d890748-4e3b-4d17-9ab7-351e451beffd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ac54d8d-193e-4100-ba32-8643f1840b31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ac54d8d-193e-4100-ba32-8643f1840b31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ac54d8d-193e-4100-ba32-8643f1840b31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Sentiment\n",
              "count  16479.000000\n",
              "mean       0.202075\n",
              "std        0.771074\n",
              "min       -1.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpryPsS6XC52",
        "outputId": "ca94412a-e7e6-48b1-bd2f-c2e21aa9f22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text         11842\n",
              "Sentiment        3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5j7IjmXC52",
        "outputId": "100b5ea1-996f-45b1-ad6b-d1a6a104da3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max words: 81\n",
            "Min words: 2,\n",
            "Avg words: 19.162752594210815\n"
          ]
        }
      ],
      "source": [
        "data['Num_Words'] = data['Text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "max_words = data['Num_Words'].max()\n",
        "min_words = data['Num_Words'].min()\n",
        "avg_words = data['Num_Words'].mean()\n",
        "\n",
        "print(f\"Max words: {max_words}\\nMin words: {min_words},\\nAvg words: {avg_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taTJmkXZXC52",
        "outputId": "c187546a-1bad-486c-d16c-fd78ca76987c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment\n",
              " 1    6900\n",
              " 0    6009\n",
              "-1    3570\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_counts = data['Sentiment'].value_counts()\n",
        "sentiment_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "vk0bw6uNXC53",
        "outputId": "ee2963e4-26f7-49f9-b84c-8da73ecbade3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Sentiment', data=data)\n",
        "plt.title('Distribution of Labels in Training Set')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "9zqr1NJzXC53",
        "outputId": "48cdfd01-0c6d-462c-c52e-fb1d99f0aa93"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "avg_words_per_category = data.groupby('Sentiment')['Num_Words'].mean()\n",
        "\n",
        "avg_words_per_category.plot(kind='bar')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Average Number of Words')\n",
        "plt.title('Average Words per Sentiment')\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y3fzAxPXC53"
      },
      "source": [
        "## Preprocessing\n",
        "We need to preprocess the data to make it readable for the model.\n",
        "\n",
        "**Steps**:\n",
        "1. We need to drop all duplicates\n",
        "\n",
        "2. We need to remove all the stop words in the text using `nltk`'s stopwords.\n",
        "\n",
        "3. We need to remove HTML tags, URLs, special characters, and convert to lowercase.\n",
        "\n",
        "4. We need to find unique words in dataset (using `Counter()`) to count each word's occurence and convert text to integers. Then we will create a mapping to map each unique word to integer.\n",
        "\n",
        "5. We need to make the sequences same length. The sequences that don't meet that length will be padded with '0's' while the longer ones will be cut. We will define same-length sequences by:\n",
        "    - If sequence length < 200: left-pad with zeros\n",
        "    - If sequence length > 200: use the last 200 elements\n",
        "\n",
        "6. Use `train_test_split` to get an 80/20 split of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MipyD_9eXC53"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates(subset=['Text'], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVj1dT9aXC53",
        "outputId": "9da27f0f-8a44-4f41-8bfb-97a755f6bba6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ffj9GEgTXC53"
      },
      "outputs": [],
      "source": [
        "data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ejNJDbyjXC54"
      },
      "outputs": [],
      "source": [
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6Mwq-1XC54",
        "outputId": "9ea7ebde-b989-404d-c45c-25a0044b7bf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Counting words occurences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n",
            "Map sentiments to ints\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eur', 's', 'company', 'aap', 'user']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ]
        }
      ],
      "source": [
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(data['Text']),\n",
        "                       title='Counting words occurences')\n",
        "for i, sentiment in enumerate(data['Text']):\n",
        "    text = ''.join([c if c not in punctuation else ' '+c+' ' for c in sentiment]).lower()\n",
        "    data.loc[i,'Text'] = text\n",
        "    pbar.update()\n",
        "    counts.update(text.split())\n",
        "\n",
        "\n",
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "print(word_counts[:5])\n",
        "word_to_int = {word: ii for ii, word in enumerate(word_counts, 1)}\n",
        "\n",
        "mapped_sentiment = []\n",
        "pbar = pyprind.ProgBar(len(data['Text']),\n",
        "                       title='Map sentiments to ints')\n",
        "for sentiment in data['Text']:\n",
        "    mapped_sentiment.append([word_to_int[word] for word in sentiment.split()])\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6657k-P6XC54"
      },
      "outputs": [],
      "source": [
        "sequence_length = 200\n",
        "sequences = np.zeros((len(mapped_sentiment), sequence_length), dtype=int)\n",
        "for i, row in enumerate(mapped_sentiment):\n",
        "    if row: # Check if the row is not empty\n",
        "        sentiment_arr = np.array(row)\n",
        "        sequences[i, -len(row):] = sentiment_arr[-sequence_length:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HLF7urkhXC54"
      },
      "outputs": [],
      "source": [
        "X = sequences\n",
        "y = data['Sentiment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJyqFK6XC54",
        "outputId": "39647a31-2056-4d13-deb3-1931b5c9cae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   514,    90,   140],\n",
              "       [    0,     0,     0, ...,     4,    40,    52],\n",
              "       [    0,     0,     0, ...,    18, 14794,   312],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,  1398,    68,    56],\n",
              "       [    0,     0,     0, ...,  5950,   370,   767],\n",
              "       [    0,     0,     0, ...,  2276,   755,    16]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWtIT1mhXC54",
        "outputId": "62d1ff22-0fd4-4b6b-c290-4f5b6de81cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9473, 200) (9473,) (2369, 200) (2369,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPn66AytXC55"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "The `SentimentRNN` class implements a recurrent neural network (RNN) for sentiment analysis using TensorFlow and Keras. It utilizes an **embedding layer** followed by **LSTM** (Long Short-Term Memory) layers with bidirectional processing to capture sequential dependencies effectively. Dropout regularization is applied to mitigate overfitting, and the final output layer uses a sigmoid activation function for binary classification. This architecture leverages the strengths of LSTM networks for handling sequential data and is suitable for tasks like sentiment analysis where understanding the context and dependencies among words is crucial for accurate classification:\n",
        "\n",
        "**Embedding Layer:**\n",
        "  - **Input:**\n",
        "    - Dimension of the vocabulary (`n_words`)\n",
        "    - Input sequence length (`seq_len`)\n",
        "  - **Functionality:**\n",
        "    - Maps each word index to a dense vector representation (`embed_size`)\n",
        "   \n",
        "**LSTM Layers:**\n",
        "  - **Bidirectional LSTM:**\n",
        "    - **Units:** `lstm_size`\n",
        "    - **Number of Layers:** `num_layers`\n",
        "    - **Return Sequences:** True for all layers except the last one\n",
        "    - **Functionality:**\n",
        "      - Captures forward and backward context of the input sequences\n",
        "      - Helps in understanding context from both past and future states\n",
        "\n",
        "**Dropout Layers:**\n",
        "  - **Usage:**\n",
        "    - Applied after each LSTM layer (`Dropout(0.5)`)\n",
        "    - Reduces overfitting by randomly setting a fraction of inputs to zero during training\n",
        "   \n",
        "**Dense Output Layer:**\n",
        "  - **Activation:** Sigmoid\n",
        "  - **Functionality:**\n",
        "    - Outputs a single probability score for binary sentiment classification\n",
        "\n",
        "**Optimizer and Loss Function:**\n",
        "  - **Optimizer:** Adam with a learning rate (`learning_rate`)\n",
        "  - **Loss Function:** Binary Cross-Entropy\n",
        "  - **Metrics:** Accuracy for evaluation during training\n",
        "   \n",
        "**Training:**\n",
        "  - Input: `X_train` (numpy array of shape `(num_samples, seq_len)`)\n",
        "  - Labels: `y_train` (numpy array of shape `(num_samples,)`)\n",
        "  - Trains the model using `num_epochs` with a batch size of `batch_size`\n",
        "  - Validates on 10% of the training data (`validation_split=0.1`)\n",
        "\n",
        "**Prediction:**\n",
        "  - Input: `X_data` (numpy array of shape `(num_samples, seq_len)`)\n",
        "  - Returns either predicted labels (`numpy.ndarray` of integers) or probabilities (`numpy.ndarray` of floats) based on the `return_proba` parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zmXxUnXdXC55"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN:\n",
        "    \"\"\"\n",
        "    A Recurrent Neural Network model for sentiment analysis using TensorFlow and Keras.\n",
        "\n",
        "    Methods:\n",
        "        build_model():\n",
        "            Builds the RNN model using TensorFlow and Keras.\n",
        "\n",
        "        train(X_train, y_train, num_epochs):\n",
        "            Trains the RNN model on the provided training data.\n",
        "\n",
        "        predict(X_data, return_proba=False):\n",
        "            Makes predictions on new data.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_words, seq_len=200,\n",
        "                 lstm_size=256, num_layers=1, batch_size=64,\n",
        "                 learning_rate=0.0001, embed_size=200):\n",
        "        \"\"\"\n",
        "        Initializes the SentimentRNN object with specified parameters.\n",
        "\n",
        "        Args:\n",
        "            n_words (int): Number of words in the vocabulary.\n",
        "            seq_len (int, optional): Length of input sequences (default is 200).\n",
        "            lstm_size (int, optional): Size of LSTM units (default is 256).\n",
        "            num_layers (int, optional): Number of LSTM layers (default is 1).\n",
        "            batch_size (int, optional): Batch size for training (default is 64).\n",
        "            learning_rate (float, optional): Learning rate for the optimizer (default is 0.0001).\n",
        "            embed_size (int, optional): Size of word embeddings (default is 200).\n",
        "        \"\"\"\n",
        "        self.n_words = n_words\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the LSTM-based sentiment analysis model using tf.keras.Sequential.\n",
        "        Embedding layer, LSTM layers (with dropout), and Dense output layer are added.\n",
        "        Adam optimizer is used with binary cross-entropy loss.\n",
        "        \"\"\"\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(input_dim=self.n_words, output_dim=self.embed_size, input_length=self.seq_len))\n",
        "        for _ in range(self.num_layers):\n",
        "            self.model.add(Bidirectional(LSTM(self.lstm_size, return_sequences=True)))\n",
        "            self.model.add(Dropout(0.5))\n",
        "        self.model.add(Bidirectional(LSTM(self.lstm_size)))\n",
        "        self.model.add(Dropout(0.5))\n",
        "        self.model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
        "                           loss='binary_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "        # self.model.summary()\n",
        "\n",
        "    def train(self, X_train, y_train, num_epochs):\n",
        "        \"\"\"\n",
        "        Trains the sentiment analysis model on the provided training data.\n",
        "\n",
        "        Args:\n",
        "            X_train (numpy.ndarray): Training input data of shape (num_samples, seq_len).\n",
        "            y_train (numpy.ndarray): Training labels of shape (num_samples,).\n",
        "            num_epochs (int): Number of epochs to train the model.\n",
        "        \"\"\"\n",
        "        self.model.fit(X_train, y_train, epochs=num_epochs, batch_size=self.batch_size, validation_split=0.1)\n",
        "\n",
        "    def predict(self, X_data, return_proba=False):\n",
        "        \"\"\"\n",
        "        Predicts sentiment labels or probabilities for input data.\n",
        "\n",
        "        Args:\n",
        "            X_data (numpy.ndarray): Input data of shape (num_samples, seq_len).\n",
        "            return_proba (bool, optional): If True, returns predicted probabilities; otherwise, returns labels (default is False).\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted labels (if return_proba=False) or probabilities (if return_proba=True).\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(X_data, batch_size=self.batch_size)\n",
        "        if return_proba:\n",
        "            return predictions\n",
        "        else:\n",
        "            return (predictions > 0.5).astype(np.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**n_words**: Check the maximum index value in X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Mm0UyTDpXC55"
      },
      "outputs": [],
      "source": [
        "n_words = max(list(word_to_int.values())) + 1\n",
        "rnn = SentimentRNN(n_words=n_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_PBsdcWXC55"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxyxYLNzXC55",
        "outputId": "3007c7ee-c71e-4466-d329-cdf25d1d793a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 45s 197ms/step - loss: 0.5483 - accuracy: 0.2548 - val_loss: 0.5714 - val_accuracy: 0.2468\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.3921 - accuracy: 0.2929 - val_loss: -0.3759 - val_accuracy: 0.4631\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 15s 110ms/step - loss: -3.6890 - accuracy: 0.5663 - val_loss: -2.8868 - val_accuracy: 0.5148\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 14s 105ms/step - loss: -6.5575 - accuracy: 0.6116 - val_loss: -2.3620 - val_accuracy: 0.5053\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 14s 103ms/step - loss: -8.8921 - accuracy: 0.6378 - val_loss: -3.2432 - val_accuracy: 0.5274\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 13s 96ms/step - loss: -11.0196 - accuracy: 0.6499 - val_loss: -2.6362 - val_accuracy: 0.5264\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 13s 94ms/step - loss: -12.9964 - accuracy: 0.6583 - val_loss: -3.7933 - val_accuracy: 0.5316\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 13s 96ms/step - loss: -14.0648 - accuracy: 0.6544 - val_loss: -3.8935 - val_accuracy: 0.5285\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 12s 93ms/step - loss: -14.5909 - accuracy: 0.6413 - val_loss: -3.8370 - val_accuracy: 0.5158\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 13s 94ms/step - loss: -17.5514 - accuracy: 0.6621 - val_loss: -2.2683 - val_accuracy: 0.5021\n"
          ]
        }
      ],
      "source": [
        "rnn.train(X_train, y_train, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVH3X0wTXC55",
        "outputId": "a59d5df3-adb0-459f-db97-744565b67aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 2s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = rnn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJNu_40DXC55",
        "outputId": "4f091ef3-15f2-4a8f-a5e3-6abcc5d0faec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 35.35%\n"
          ]
        }
      ],
      "source": [
        "accuracy = np.mean(preds == y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJA-ScnXC55"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "Let's see if we can increase the accuracy of this model. We will use GridSearch, but first, we need to create a wrapper for our model in order to use it.\n",
        "\n",
        "The following hyperparameters have a great effect on the model's performance:\n",
        "- `seq_len`: Affects how much contextual information the model can capture from each input text\n",
        "- `lstm_size`: Directly impacts the model's capacity to learn complex patterns and dependencies within the data\n",
        "- `num_layers`: Allows the model to learn hierarchical representations of text data, potentially improving its ability to understand nuanced sentiment expressions\n",
        "- `batch_size`: Affects the gradient update dynamics and training stability\n",
        "- `learning_rate`: Controls how much to update the model in response to estimated gradients\n",
        "\n",
        "In consideration of run time, I chose to focus on `lstm_size`, `num_layers`, and `learning_rate` as I felt that these were the most influential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Sf5c6c0hXC55"
      },
      "outputs": [],
      "source": [
        "class SentimentRNNWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_words, seq_len=200, lstm_size=256, num_layers=1,\n",
        "                 batch_size=64, learning_rate=0.0001, embed_size=200):\n",
        "        self.n_words = n_words\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, num_epochs=10):\n",
        "        \"\"\"Fit method for GridSearchCV compatibility.\n",
        "\n",
        "        Args:\n",
        "            X: X training data\n",
        "            y: y training data\n",
        "            num_epochs (int, optional): _description_. Defaults to 5.\n",
        "\n",
        "        Returns:\n",
        "            _type_: _description_\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, estimator=self, dtype=None)\n",
        "\n",
        "        self.model = SentimentRNN(\n",
        "            n_words=self.n_words,\n",
        "            seq_len=self.seq_len,\n",
        "            lstm_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            batch_size=self.batch_size,\n",
        "            learning_rate=self.learning_rate,\n",
        "            embed_size=self.embed_size\n",
        "        )\n",
        "\n",
        "        self.model.train(X, y, num_epochs=num_epochs)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict method for GridSearchCV compatibility\n",
        "\n",
        "        Args:\n",
        "            X: Assumes X is the test data\n",
        "\n",
        "        Returns:\n",
        "            predictions: Predictions made by the model\n",
        "        \"\"\"\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"Get parameters for the estimator. This is for GridSearchCV compatibility.\n",
        "\n",
        "        Args:\n",
        "            deep (bool, optional): Controls the depth of the attributes that are included in the returned dictionary of parameters. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            params: Dictionary of parameters\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'n_words': self.n_words,\n",
        "            'seq_len': self.seq_len,\n",
        "            'lstm_size': self.lstm_size,\n",
        "            'num_layers': self.num_layers,\n",
        "            'batch_size': self.batch_size,\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'embed_size': self.embed_size\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        \"\"\"Set the parameters of the estimator. This is for GridSearchCV compatibility.\n",
        "\n",
        "        Returns:\n",
        "            params: Sets the dictionary of parameters\n",
        "        \"\"\"\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5pgBfQ0xXC55"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('rnn', SentimentRNNWrapper(n_words=n_words)),\n",
        "])\n",
        "\n",
        "# Define parameters for grid search\n",
        "parameters = {\n",
        "    # 'rnn__seq_len': [100, 200, 300],\n",
        "    'rnn__lstm_size': [128, 256, 512],\n",
        "    'rnn__num_layers': [1, 2, 3],\n",
        "    # 'rnn__batch_size': [32, 64, 128],\n",
        "    'rnn__learning_rate': [0.001, 0.0001],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dz6eZ_vQXC55"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(pipeline, parameters, cv=2, verbose=1, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SfGhiFNGXC55",
        "outputId": "dfd8018d-bc50-4fdd-8766-2690bf95b91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 17s 141ms/step - loss: 0.5413 - accuracy: 0.2630 - val_loss: 0.5219 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 6s 90ms/step - loss: -1.7443 - accuracy: 0.5153 - val_loss: 0.6617 - val_accuracy: 0.4852\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 5s 73ms/step - loss: -7.0247 - accuracy: 0.6183 - val_loss: -0.1424 - val_accuracy: 0.5021\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 5s 75ms/step - loss: -10.6016 - accuracy: 0.6333 - val_loss: 3.3503 - val_accuracy: 0.4494\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 4s 55ms/step - loss: -13.8690 - accuracy: 0.6373 - val_loss: 2.6076 - val_accuracy: 0.4873\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 4s 58ms/step - loss: -18.3009 - accuracy: 0.6499 - val_loss: -2.0224 - val_accuracy: 0.4895\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 4s 59ms/step - loss: -17.8374 - accuracy: 0.5603 - val_loss: -0.9940 - val_accuracy: 0.3481\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 4s 55ms/step - loss: -26.5666 - accuracy: 0.6204 - val_loss: -3.7535 - val_accuracy: 0.4705\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 4s 53ms/step - loss: -31.5321 - accuracy: 0.6563 - val_loss: -3.3704 - val_accuracy: 0.4726\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 3s 51ms/step - loss: -34.9168 - accuracy: 0.6321 - val_loss: 5.6658 - val_accuracy: 0.4325\n",
            "75/75 [==============================] - 3s 21ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 17s 152ms/step - loss: 0.5257 - accuracy: 0.2599 - val_loss: 0.2561 - val_accuracy: 0.4473\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 6s 84ms/step - loss: -2.3026 - accuracy: 0.5498 - val_loss: -1.0312 - val_accuracy: 0.4958\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 5s 83ms/step - loss: -8.1521 - accuracy: 0.6404 - val_loss: -2.1757 - val_accuracy: 0.4916\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 4s 67ms/step - loss: -12.8229 - accuracy: 0.6495 - val_loss: -3.6671 - val_accuracy: 0.4578\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 4s 63ms/step - loss: -18.8557 - accuracy: 0.6819 - val_loss: -4.3855 - val_accuracy: 0.5063\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 4s 59ms/step - loss: -23.8719 - accuracy: 0.6805 - val_loss: -3.7667 - val_accuracy: 0.4979\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 3s 49ms/step - loss: -27.8981 - accuracy: 0.6796 - val_loss: -5.5805 - val_accuracy: 0.4937\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 4s 56ms/step - loss: -32.1582 - accuracy: 0.6817 - val_loss: -3.0306 - val_accuracy: 0.4958\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 3s 52ms/step - loss: -35.6345 - accuracy: 0.6836 - val_loss: -1.2001 - val_accuracy: 0.4895\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 3s 46ms/step - loss: -41.4084 - accuracy: 0.6939 - val_loss: -4.9098 - val_accuracy: 0.5000\n",
            "74/74 [==============================] - 2s 17ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 22s 188ms/step - loss: 0.5138 - accuracy: 0.2848 - val_loss: 0.2916 - val_accuracy: 0.4684\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 7s 104ms/step - loss: -1.7854 - accuracy: 0.4998 - val_loss: -1.5331 - val_accuracy: 0.4219\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 7s 105ms/step - loss: 1.5416 - accuracy: 0.3728 - val_loss: 0.5022 - val_accuracy: 0.2363\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 6s 88ms/step - loss: -1.6786 - accuracy: 0.5420 - val_loss: 0.7151 - val_accuracy: 0.4620\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 6s 86ms/step - loss: -6.4461 - accuracy: 0.6396 - val_loss: -0.5798 - val_accuracy: 0.5042\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 5s 81ms/step - loss: -10.0967 - accuracy: 0.6537 - val_loss: -0.6243 - val_accuracy: 0.4641\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 5s 79ms/step - loss: -13.5965 - accuracy: 0.6743 - val_loss: 0.9924 - val_accuracy: 0.4958\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 5s 75ms/step - loss: -15.4750 - accuracy: 0.6649 - val_loss: -0.0669 - val_accuracy: 0.4219\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 5s 75ms/step - loss: -17.3137 - accuracy: 0.6485 - val_loss: 2.7852 - val_accuracy: 0.4451\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 5s 78ms/step - loss: -20.6755 - accuracy: 0.6509 - val_loss: 5.7859 - val_accuracy: 0.4747\n",
            "75/75 [==============================] - 4s 25ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 23s 195ms/step - loss: 0.5238 - accuracy: 0.2662 - val_loss: 0.1939 - val_accuracy: 0.4262\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 8s 124ms/step - loss: -1.7668 - accuracy: 0.5552 - val_loss: 1.1955 - val_accuracy: 0.4536\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 6s 88ms/step - loss: -5.9768 - accuracy: 0.6005 - val_loss: -1.4023 - val_accuracy: 0.4937\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -10.7713 - accuracy: 0.6008 - val_loss: -3.0456 - val_accuracy: 0.4895\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 6s 83ms/step - loss: -15.3184 - accuracy: 0.6746 - val_loss: -4.6653 - val_accuracy: 0.5190\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 6s 86ms/step - loss: -19.5205 - accuracy: 0.6744 - val_loss: -5.0990 - val_accuracy: 0.4895\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 6s 84ms/step - loss: -24.9449 - accuracy: 0.6779 - val_loss: -6.5337 - val_accuracy: 0.5190\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 5s 79ms/step - loss: -28.9062 - accuracy: 0.6580 - val_loss: -8.4588 - val_accuracy: 0.5316\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 5s 76ms/step - loss: -34.5594 - accuracy: 0.6958 - val_loss: -4.9223 - val_accuracy: 0.5359\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 5s 77ms/step - loss: -36.1319 - accuracy: 0.6671 - val_loss: -6.5238 - val_accuracy: 0.5295\n",
            "74/74 [==============================] - 4s 26ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 27s 203ms/step - loss: 0.5706 - accuracy: 0.2609 - val_loss: 0.5708 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 10s 156ms/step - loss: -0.6881 - accuracy: 0.4404 - val_loss: 0.1080 - val_accuracy: 0.4030\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 7s 111ms/step - loss: -5.2780 - accuracy: 0.5901 - val_loss: 0.2843 - val_accuracy: 0.4641\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 112ms/step - loss: -4.9743 - accuracy: 0.6032 - val_loss: 0.6633 - val_accuracy: 0.5021\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 99ms/step - loss: -5.8094 - accuracy: 0.6039 - val_loss: 1.1837 - val_accuracy: 0.5021\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 98ms/step - loss: -8.2534 - accuracy: 0.6004 - val_loss: 1.4925 - val_accuracy: 0.5021\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 97ms/step - loss: -10.4176 - accuracy: 0.5985 - val_loss: 1.5406 - val_accuracy: 0.5021\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -12.6931 - accuracy: 0.5983 - val_loss: 1.7579 - val_accuracy: 0.5042\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 97ms/step - loss: -14.7661 - accuracy: 0.6110 - val_loss: 2.5360 - val_accuracy: 0.4937\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -17.2178 - accuracy: 0.6208 - val_loss: 4.3442 - val_accuracy: 0.4895\n",
            "75/75 [==============================] - 5s 33ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 27s 200ms/step - loss: 0.5443 - accuracy: 0.2585 - val_loss: 0.3670 - val_accuracy: 0.3249\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 8s 127ms/step - loss: -1.7794 - accuracy: 0.5473 - val_loss: -0.7987 - val_accuracy: 0.4916\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 8s 127ms/step - loss: -7.4489 - accuracy: 0.6350 - val_loss: -0.0788 - val_accuracy: 0.4789\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 108ms/step - loss: -12.7608 - accuracy: 0.6636 - val_loss: -2.0760 - val_accuracy: 0.4515\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -18.0700 - accuracy: 0.6887 - val_loss: -2.6324 - val_accuracy: 0.5148\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 102ms/step - loss: -22.2236 - accuracy: 0.6948 - val_loss: -0.6789 - val_accuracy: 0.5084\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 99ms/step - loss: -24.6937 - accuracy: 0.6814 - val_loss: -5.4100 - val_accuracy: 0.4979\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -28.5297 - accuracy: 0.6742 - val_loss: -3.6635 - val_accuracy: 0.5084\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -29.8761 - accuracy: 0.5878 - val_loss: -3.1191 - val_accuracy: 0.4937\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 6s 94ms/step - loss: -33.6207 - accuracy: 0.6580 - val_loss: -2.8126 - val_accuracy: 0.4831\n",
            "74/74 [==============================] - 5s 33ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 19s 179ms/step - loss: 0.5457 - accuracy: 0.2630 - val_loss: 0.2257 - val_accuracy: 0.4051\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 9s 134ms/step - loss: -1.3279 - accuracy: 0.5099 - val_loss: 1.1025 - val_accuracy: 0.4873\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 8s 114ms/step - loss: -9.8992 - accuracy: 0.6037 - val_loss: 1.0607 - val_accuracy: 0.4768\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 101ms/step - loss: -17.6559 - accuracy: 0.6171 - val_loss: -8.2924 - val_accuracy: 0.5190\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 99ms/step - loss: -27.9092 - accuracy: 0.6443 - val_loss: -1.3209 - val_accuracy: 0.5211\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 105ms/step - loss: -37.7307 - accuracy: 0.6779 - val_loss: 0.5861 - val_accuracy: 0.5169\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 98ms/step - loss: -46.3049 - accuracy: 0.6886 - val_loss: 3.0868 - val_accuracy: 0.5105\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 100ms/step - loss: -53.3163 - accuracy: 0.6877 - val_loss: 4.2873 - val_accuracy: 0.5127\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 7s 104ms/step - loss: -59.9766 - accuracy: 0.6814 - val_loss: 0.0519 - val_accuracy: 0.5021\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -64.7368 - accuracy: 0.6701 - val_loss: 26.7811 - val_accuracy: 0.4451\n",
            "75/75 [==============================] - 4s 32ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 19s 188ms/step - loss: 0.5130 - accuracy: 0.2723 - val_loss: 0.3015 - val_accuracy: 0.4325\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 8s 127ms/step - loss: -3.4636 - accuracy: 0.5156 - val_loss: -0.1355 - val_accuracy: 0.4937\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 7s 112ms/step - loss: -12.1995 - accuracy: 0.6125 - val_loss: 0.0653 - val_accuracy: 0.5021\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 107ms/step - loss: -21.2516 - accuracy: 0.6524 - val_loss: -2.9275 - val_accuracy: 0.4789\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 108ms/step - loss: -29.9313 - accuracy: 0.6704 - val_loss: -3.6804 - val_accuracy: 0.4916\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -33.9644 - accuracy: 0.6568 - val_loss: -1.5927 - val_accuracy: 0.4705\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 97ms/step - loss: -37.5128 - accuracy: 0.6341 - val_loss: 2.3586 - val_accuracy: 0.4662\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 6s 94ms/step - loss: -37.1927 - accuracy: 0.6240 - val_loss: 0.5178 - val_accuracy: 0.4599\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -44.7470 - accuracy: 0.6186 - val_loss: 2.2983 - val_accuracy: 0.4557\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 7s 98ms/step - loss: -58.2355 - accuracy: 0.6528 - val_loss: -3.1477 - val_accuracy: 0.4536\n",
            "74/74 [==============================] - 4s 31ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 26s 239ms/step - loss: 0.5080 - accuracy: 0.2877 - val_loss: 0.2090 - val_accuracy: 0.4008\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 12s 179ms/step - loss: -1.7713 - accuracy: 0.4463 - val_loss: 0.9942 - val_accuracy: 0.3523\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 11s 172ms/step - loss: -7.9563 - accuracy: 0.5181 - val_loss: -2.4126 - val_accuracy: 0.4662\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 11s 162ms/step - loss: -16.6485 - accuracy: 0.5500 - val_loss: -0.4725 - val_accuracy: 0.4726\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 10s 154ms/step - loss: -23.6648 - accuracy: 0.5861 - val_loss: -1.5234 - val_accuracy: 0.4346\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 10s 152ms/step - loss: -31.9667 - accuracy: 0.6314 - val_loss: -1.0392 - val_accuracy: 0.4726\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 10s 145ms/step - loss: -35.7079 - accuracy: 0.6438 - val_loss: -6.9141 - val_accuracy: 0.4768\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 10s 151ms/step - loss: -43.5945 - accuracy: 0.6551 - val_loss: -6.8059 - val_accuracy: 0.5021\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 10s 146ms/step - loss: -51.8880 - accuracy: 0.6692 - val_loss: -2.8140 - val_accuracy: 0.4662\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 10s 144ms/step - loss: -59.3811 - accuracy: 0.6563 - val_loss: -6.8119 - val_accuracy: 0.5105\n",
            "75/75 [==============================] - 6s 50ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 25s 240ms/step - loss: 0.4647 - accuracy: 0.2836 - val_loss: -0.1572 - val_accuracy: 0.4367\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 12s 179ms/step - loss: -0.6061 - accuracy: 0.3964 - val_loss: 0.1688 - val_accuracy: 0.2785\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 11s 166ms/step - loss: -5.1633 - accuracy: 0.5269 - val_loss: -2.0160 - val_accuracy: 0.5021\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 10s 149ms/step - loss: -11.4570 - accuracy: 0.5714 - val_loss: -1.7820 - val_accuracy: 0.4810\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 10s 149ms/step - loss: -17.6419 - accuracy: 0.6033 - val_loss: -0.8325 - val_accuracy: 0.4367\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 10s 153ms/step - loss: -23.8561 - accuracy: 0.6301 - val_loss: -0.7215 - val_accuracy: 0.4873\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 10s 148ms/step - loss: -30.8033 - accuracy: 0.6538 - val_loss: -2.6831 - val_accuracy: 0.4789\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 10s 151ms/step - loss: -38.1437 - accuracy: 0.6599 - val_loss: -5.2445 - val_accuracy: 0.4895\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 10s 146ms/step - loss: -43.2334 - accuracy: 0.6484 - val_loss: -2.4987 - val_accuracy: 0.4578\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 10s 144ms/step - loss: -45.4827 - accuracy: 0.6345 - val_loss: -1.5576 - val_accuracy: 0.4620\n",
            "74/74 [==============================] - 6s 50ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 34s 305ms/step - loss: 0.5210 - accuracy: 0.2870 - val_loss: 0.2975 - val_accuracy: 0.2954\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 16s 241ms/step - loss: -3.4474 - accuracy: 0.5460 - val_loss: -0.4730 - val_accuracy: 0.5232\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 14s 209ms/step - loss: -9.2896 - accuracy: 0.6190 - val_loss: -1.5125 - val_accuracy: 0.4620\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 14s 206ms/step - loss: -8.1196 - accuracy: 0.5641 - val_loss: 3.3602 - val_accuracy: 0.3945\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 13s 199ms/step - loss: -15.7527 - accuracy: 0.5955 - val_loss: 3.8504 - val_accuracy: 0.4409\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 13s 196ms/step - loss: -22.0187 - accuracy: 0.6363 - val_loss: 3.4632 - val_accuracy: 0.4747\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 14s 203ms/step - loss: -27.9148 - accuracy: 0.6473 - val_loss: 4.9313 - val_accuracy: 0.4705\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 13s 198ms/step - loss: -34.1206 - accuracy: 0.6544 - val_loss: 10.0724 - val_accuracy: 0.4515\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 13s 198ms/step - loss: -12.3272 - accuracy: 0.4174 - val_loss: 0.5848 - val_accuracy: 0.2384\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 13s 195ms/step - loss: 0.3167 - accuracy: 0.3742 - val_loss: 0.5057 - val_accuracy: 0.2405\n",
            "75/75 [==============================] - 7s 68ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 33s 290ms/step - loss: 0.5804 - accuracy: 0.2564 - val_loss: 0.4111 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 15s 224ms/step - loss: -1.7963 - accuracy: 0.4687 - val_loss: -0.0618 - val_accuracy: 0.4304\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 14s 216ms/step - loss: -6.4807 - accuracy: 0.5925 - val_loss: -0.6027 - val_accuracy: 0.4726\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 14s 205ms/step - loss: -8.8833 - accuracy: 0.5372 - val_loss: -0.4412 - val_accuracy: 0.4810\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 14s 203ms/step - loss: -12.3800 - accuracy: 0.5665 - val_loss: 0.9858 - val_accuracy: 0.4367\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 13s 202ms/step - loss: -15.8058 - accuracy: 0.5965 - val_loss: 3.0084 - val_accuracy: 0.2743\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 13s 191ms/step - loss: -18.3510 - accuracy: 0.5972 - val_loss: 1.9565 - val_accuracy: 0.4325\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 13s 200ms/step - loss: -25.4401 - accuracy: 0.6233 - val_loss: -2.9207 - val_accuracy: 0.4515\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 13s 197ms/step - loss: -28.7913 - accuracy: 0.6040 - val_loss: 7.2504 - val_accuracy: 0.4430\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 13s 196ms/step - loss: -30.2423 - accuracy: 0.6179 - val_loss: 11.6303 - val_accuracy: 0.4262\n",
            "74/74 [==============================] - 7s 69ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 29s 317ms/step - loss: 0.4664 - accuracy: 0.2935 - val_loss: 1.3277 - val_accuracy: 0.4789\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 20s 300ms/step - loss: -4.3647 - accuracy: 0.5462 - val_loss: -0.3889 - val_accuracy: 0.3924\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 19s 280ms/step - loss: -14.3406 - accuracy: 0.5603 - val_loss: -3.2416 - val_accuracy: 0.3629\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 19s 284ms/step - loss: -28.2657 - accuracy: 0.6192 - val_loss: 2.7894 - val_accuracy: 0.4430\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 19s 281ms/step - loss: -40.1725 - accuracy: 0.6070 - val_loss: 7.6632 - val_accuracy: 0.4662\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 18s 276ms/step - loss: -48.5220 - accuracy: 0.5915 - val_loss: 0.6554 - val_accuracy: 0.4810\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 18s 266ms/step - loss: -61.1704 - accuracy: 0.5866 - val_loss: -1.9865 - val_accuracy: 0.4916\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 18s 276ms/step - loss: -46.3735 - accuracy: 0.5685 - val_loss: -14.4297 - val_accuracy: 0.4620\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 18s 270ms/step - loss: -54.3585 - accuracy: 0.5854 - val_loss: 7.3357 - val_accuracy: 0.4367\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 18s 273ms/step - loss: -69.8412 - accuracy: 0.6056 - val_loss: 10.2667 - val_accuracy: 0.4325\n",
            "75/75 [==============================] - 9s 89ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 29s 341ms/step - loss: 0.4576 - accuracy: 0.2867 - val_loss: 0.3279 - val_accuracy: 0.2975\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 20s 298ms/step - loss: -5.3759 - accuracy: 0.5219 - val_loss: -2.7318 - val_accuracy: 0.4557\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 19s 288ms/step - loss: -13.5966 - accuracy: 0.5550 - val_loss: -2.7921 - val_accuracy: 0.4705\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 18s 266ms/step - loss: -28.6623 - accuracy: 0.6139 - val_loss: -4.3887 - val_accuracy: 0.4599\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 19s 280ms/step - loss: -40.0977 - accuracy: 0.5630 - val_loss: -11.1103 - val_accuracy: 0.4557\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 18s 275ms/step - loss: -38.9722 - accuracy: 0.4846 - val_loss: -13.4343 - val_accuracy: 0.4620\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 18s 267ms/step - loss: -68.9578 - accuracy: 0.5679 - val_loss: -13.4713 - val_accuracy: 0.4641\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 18s 265ms/step - loss: -89.1886 - accuracy: 0.6061 - val_loss: -8.5148 - val_accuracy: 0.4578\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 18s 265ms/step - loss: -108.2055 - accuracy: 0.6094 - val_loss: -13.3964 - val_accuracy: 0.4747\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 18s 271ms/step - loss: -126.5229 - accuracy: 0.6277 - val_loss: -24.8347 - val_accuracy: 0.5105\n",
            "74/74 [==============================] - 8s 90ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 43s 497ms/step - loss: 0.5239 - accuracy: 0.2881 - val_loss: 0.2441 - val_accuracy: 0.4241\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 30s 448ms/step - loss: 0.6697 - accuracy: 0.3114 - val_loss: 0.5839 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 30s 444ms/step - loss: 0.5589 - accuracy: 0.2656 - val_loss: 0.6247 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 30s 447ms/step - loss: 0.5542 - accuracy: 0.2644 - val_loss: 0.6081 - val_accuracy: 0.2384\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 29s 437ms/step - loss: 0.5677 - accuracy: 0.2616 - val_loss: 0.5813 - val_accuracy: 0.2384\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 29s 439ms/step - loss: 0.5669 - accuracy: 0.2604 - val_loss: 0.5819 - val_accuracy: 0.2384\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 29s 433ms/step - loss: 0.5507 - accuracy: 0.2611 - val_loss: 0.5929 - val_accuracy: 0.2384\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 29s 436ms/step - loss: 0.5481 - accuracy: 0.2621 - val_loss: 0.6155 - val_accuracy: 0.2384\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 29s 435ms/step - loss: 0.5480 - accuracy: 0.2628 - val_loss: 0.5914 - val_accuracy: 0.2384\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 29s 435ms/step - loss: 0.5429 - accuracy: 0.2611 - val_loss: 0.5926 - val_accuracy: 0.2384\n",
            "75/75 [==============================] - 14s 142ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 43s 504ms/step - loss: 0.5474 - accuracy: 0.2714 - val_loss: 0.1412 - val_accuracy: 0.4536\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 30s 454ms/step - loss: -3.4083 - accuracy: 0.4905 - val_loss: -0.0232 - val_accuracy: 0.3544\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 30s 448ms/step - loss: -11.6080 - accuracy: 0.4893 - val_loss: -1.9515 - val_accuracy: 0.4873\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 30s 441ms/step - loss: -23.5640 - accuracy: 0.6068 - val_loss: -7.8724 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 29s 440ms/step - loss: -34.0848 - accuracy: 0.6209 - val_loss: -7.8505 - val_accuracy: 0.4599\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 29s 437ms/step - loss: -41.4627 - accuracy: 0.6024 - val_loss: -11.9226 - val_accuracy: 0.4747\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 29s 436ms/step - loss: -54.3663 - accuracy: 0.6275 - val_loss: -3.8356 - val_accuracy: 0.4536\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 29s 435ms/step - loss: -55.7979 - accuracy: 0.5991 - val_loss: -4.4554 - val_accuracy: 0.4684\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 29s 433ms/step - loss: -74.7221 - accuracy: 0.6254 - val_loss: -1.8825 - val_accuracy: 0.4536\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 29s 428ms/step - loss: -96.0672 - accuracy: 0.6512 - val_loss: -14.3661 - val_accuracy: 0.5042\n",
            "74/74 [==============================] - 14s 146ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 60s 712ms/step - loss: 0.5928 - accuracy: 0.2703 - val_loss: 0.5725 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 41s 619ms/step - loss: -0.3092 - accuracy: 0.4071 - val_loss: 0.6318 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 41s 614ms/step - loss: 0.5874 - accuracy: 0.2651 - val_loss: 0.5905 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 41s 611ms/step - loss: 0.5711 - accuracy: 0.2712 - val_loss: 0.6025 - val_accuracy: 0.2384\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 42s 625ms/step - loss: 0.5849 - accuracy: 0.2647 - val_loss: 0.5869 - val_accuracy: 0.2384\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 42s 626ms/step - loss: 0.5725 - accuracy: 0.2672 - val_loss: 0.5817 - val_accuracy: 0.2384\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 41s 610ms/step - loss: 0.1302 - accuracy: 0.3503 - val_loss: 0.5784 - val_accuracy: 0.4958\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 41s 606ms/step - loss: -4.7640 - accuracy: 0.5084 - val_loss: -0.0601 - val_accuracy: 0.4494\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 40s 602ms/step - loss: -7.9054 - accuracy: 0.4435 - val_loss: 3.7731 - val_accuracy: 0.2384\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 40s 602ms/step - loss: -12.9448 - accuracy: 0.4296 - val_loss: 4.7629 - val_accuracy: 0.2384\n",
            "75/75 [==============================] - 17s 202ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 60s 695ms/step - loss: 0.6301 - accuracy: 0.2566 - val_loss: 0.4822 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 42s 635ms/step - loss: -0.6755 - accuracy: 0.4354 - val_loss: 0.1574 - val_accuracy: 0.4852\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 42s 620ms/step - loss: -4.2709 - accuracy: 0.5311 - val_loss: 1.1043 - val_accuracy: 0.4641\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 41s 610ms/step - loss: -6.0568 - accuracy: 0.4342 - val_loss: 0.6660 - val_accuracy: 0.4030\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 42s 623ms/step - loss: -14.7565 - accuracy: 0.4513 - val_loss: 1.1147 - val_accuracy: 0.4852\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 41s 617ms/step - loss: -24.2319 - accuracy: 0.5116 - val_loss: 1.7400 - val_accuracy: 0.3650\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 41s 607ms/step - loss: -34.6909 - accuracy: 0.5531 - val_loss: 4.7446 - val_accuracy: 0.3945\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 41s 610ms/step - loss: 53.5267 - accuracy: 0.2552 - val_loss: 38.1272 - val_accuracy: 0.2743\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 41s 614ms/step - loss: 24.8600 - accuracy: 0.2611 - val_loss: 0.8999 - val_accuracy: 0.2743\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 41s 620ms/step - loss: -4.8841 - accuracy: 0.4487 - val_loss: -0.3950 - val_accuracy: 0.2743\n",
            "74/74 [==============================] - 17s 204ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 18s 139ms/step - loss: 0.5761 - accuracy: 0.2698 - val_loss: 0.5846 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 6s 89ms/step - loss: 0.5264 - accuracy: 0.2602 - val_loss: 0.5865 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 5s 69ms/step - loss: 0.5195 - accuracy: 0.2602 - val_loss: 0.5790 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 5s 70ms/step - loss: 0.4868 - accuracy: 0.2602 - val_loss: 0.5393 - val_accuracy: 0.2384\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 4s 59ms/step - loss: -0.9678 - accuracy: 0.4704 - val_loss: -0.2239 - val_accuracy: 0.4515\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 4s 54ms/step - loss: -4.0356 - accuracy: 0.6483 - val_loss: -0.9203 - val_accuracy: 0.5591\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 4s 55ms/step - loss: -5.3773 - accuracy: 0.6729 - val_loss: -0.7320 - val_accuracy: 0.5211\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 3s 51ms/step - loss: -6.2816 - accuracy: 0.6842 - val_loss: -0.6439 - val_accuracy: 0.5148\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 4s 54ms/step - loss: -7.0875 - accuracy: 0.6962 - val_loss: -0.7631 - val_accuracy: 0.5316\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 3s 50ms/step - loss: -7.9167 - accuracy: 0.7020 - val_loss: -1.0505 - val_accuracy: 0.5169\n",
            "75/75 [==============================] - 3s 18ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 16s 148ms/step - loss: 0.5913 - accuracy: 0.2494 - val_loss: 0.4991 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 6s 88ms/step - loss: 0.5423 - accuracy: 0.2465 - val_loss: 0.4839 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 5s 79ms/step - loss: 0.5330 - accuracy: 0.2465 - val_loss: 0.4751 - val_accuracy: 0.2743\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 4s 54ms/step - loss: 0.4564 - accuracy: 0.2468 - val_loss: 0.3477 - val_accuracy: 0.2743\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 4s 53ms/step - loss: -0.0378 - accuracy: 0.4551 - val_loss: 0.0954 - val_accuracy: 0.4873\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 4s 60ms/step - loss: -2.0401 - accuracy: 0.6054 - val_loss: -0.5805 - val_accuracy: 0.4916\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 4s 54ms/step - loss: -4.7572 - accuracy: 0.6631 - val_loss: -0.9734 - val_accuracy: 0.4916\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 4s 52ms/step - loss: -6.1498 - accuracy: 0.6892 - val_loss: -0.8938 - val_accuracy: 0.5063\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 4s 58ms/step - loss: -7.2443 - accuracy: 0.7026 - val_loss: -1.0920 - val_accuracy: 0.5148\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 4s 54ms/step - loss: -8.0992 - accuracy: 0.7096 - val_loss: -0.6807 - val_accuracy: 0.5190\n",
            "74/74 [==============================] - 2s 16ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 22s 177ms/step - loss: 0.5610 - accuracy: 0.2647 - val_loss: 0.5827 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 7s 107ms/step - loss: 0.5323 - accuracy: 0.2602 - val_loss: 0.5800 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 7s 101ms/step - loss: 0.5247 - accuracy: 0.2602 - val_loss: 0.5757 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 6s 83ms/step - loss: 0.4781 - accuracy: 0.2602 - val_loss: 0.4413 - val_accuracy: 0.2384\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 6s 87ms/step - loss: -1.5230 - accuracy: 0.5605 - val_loss: -0.4610 - val_accuracy: 0.4789\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 6s 87ms/step - loss: -4.4879 - accuracy: 0.6631 - val_loss: -1.3018 - val_accuracy: 0.5253\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 5s 81ms/step - loss: -5.7185 - accuracy: 0.6825 - val_loss: -1.2038 - val_accuracy: 0.5232\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 5s 75ms/step - loss: -6.7129 - accuracy: 0.6947 - val_loss: -1.4764 - val_accuracy: 0.5401\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 5s 74ms/step - loss: -7.2391 - accuracy: 0.6992 - val_loss: -1.7540 - val_accuracy: 0.5485\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 5s 80ms/step - loss: -8.0440 - accuracy: 0.7079 - val_loss: -1.4268 - val_accuracy: 0.5274\n",
            "75/75 [==============================] - 4s 26ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 20s 168ms/step - loss: 0.5717 - accuracy: 0.2503 - val_loss: 0.5060 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 8s 116ms/step - loss: 0.5431 - accuracy: 0.2465 - val_loss: 0.4892 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 6s 90ms/step - loss: 0.5367 - accuracy: 0.2465 - val_loss: 0.4931 - val_accuracy: 0.2743\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 105ms/step - loss: 0.0183 - accuracy: 0.3901 - val_loss: 0.0543 - val_accuracy: 0.4599\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 6s 86ms/step - loss: -2.9317 - accuracy: 0.6228 - val_loss: -0.5595 - val_accuracy: 0.4641\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 5s 82ms/step - loss: -4.7737 - accuracy: 0.6692 - val_loss: -0.2484 - val_accuracy: 0.4620\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 5s 77ms/step - loss: -5.8299 - accuracy: 0.6821 - val_loss: -0.1991 - val_accuracy: 0.4831\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 5s 76ms/step - loss: -6.5880 - accuracy: 0.6904 - val_loss: -0.9085 - val_accuracy: 0.5084\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 83ms/step - loss: -7.2441 - accuracy: 0.6967 - val_loss: -0.2358 - val_accuracy: 0.4831\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 5s 77ms/step - loss: -7.7596 - accuracy: 0.6995 - val_loss: -0.7360 - val_accuracy: 0.4937\n",
            "74/74 [==============================] - 4s 25ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 28s 210ms/step - loss: 0.5614 - accuracy: 0.2621 - val_loss: 0.6090 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 8s 127ms/step - loss: 0.5345 - accuracy: 0.2602 - val_loss: 0.5918 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 8s 123ms/step - loss: 0.5206 - accuracy: 0.2602 - val_loss: 0.5758 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 108ms/step - loss: 0.4043 - accuracy: 0.2853 - val_loss: 0.4480 - val_accuracy: 0.3966\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 109ms/step - loss: -1.6502 - accuracy: 0.5612 - val_loss: -0.6756 - val_accuracy: 0.5316\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 105ms/step - loss: -4.3992 - accuracy: 0.6464 - val_loss: -1.5297 - val_accuracy: 0.5443\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 100ms/step - loss: -4.6693 - accuracy: 0.6553 - val_loss: -1.2544 - val_accuracy: 0.5422\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 102ms/step - loss: -6.0956 - accuracy: 0.6912 - val_loss: -1.1678 - val_accuracy: 0.5148\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 97ms/step - loss: -7.2424 - accuracy: 0.7037 - val_loss: -1.5025 - val_accuracy: 0.5422\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 7s 100ms/step - loss: -8.0163 - accuracy: 0.7135 - val_loss: -1.2372 - val_accuracy: 0.5464\n",
            "75/75 [==============================] - 5s 33ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 29s 219ms/step - loss: 0.5784 - accuracy: 0.2491 - val_loss: 0.5014 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 9s 133ms/step - loss: 0.5458 - accuracy: 0.2465 - val_loss: 0.4853 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 8s 125ms/step - loss: 0.5435 - accuracy: 0.2465 - val_loss: 0.4888 - val_accuracy: 0.2743\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 109ms/step - loss: 0.3914 - accuracy: 0.2956 - val_loss: 0.2070 - val_accuracy: 0.4241\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 100ms/step - loss: -2.1318 - accuracy: 0.6139 - val_loss: -0.4485 - val_accuracy: 0.5063\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 102ms/step - loss: -4.4351 - accuracy: 0.6646 - val_loss: -0.6174 - val_accuracy: 0.5042\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 7s 101ms/step - loss: -5.6787 - accuracy: 0.6854 - val_loss: -0.5657 - val_accuracy: 0.5021\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 112ms/step - loss: -6.5803 - accuracy: 0.6969 - val_loss: -0.2978 - val_accuracy: 0.4873\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 95ms/step - loss: -7.1559 - accuracy: 0.6981 - val_loss: -0.5657 - val_accuracy: 0.5190\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -7.9027 - accuracy: 0.7030 - val_loss: -0.7642 - val_accuracy: 0.5127\n",
            "74/74 [==============================] - 5s 33ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 19s 174ms/step - loss: 0.5591 - accuracy: 0.2609 - val_loss: 0.5954 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 9s 131ms/step - loss: 0.5308 - accuracy: 0.2602 - val_loss: 0.5988 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 7s 110ms/step - loss: 0.5131 - accuracy: 0.2602 - val_loss: 0.5613 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 8s 116ms/step - loss: 0.7480 - accuracy: 0.3224 - val_loss: 1.0057 - val_accuracy: 0.2679\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 101ms/step - loss: 0.1170 - accuracy: 0.4359 - val_loss: 0.3029 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -1.1172 - accuracy: 0.5699 - val_loss: 1.2475 - val_accuracy: 0.4620\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -3.7437 - accuracy: 0.6180 - val_loss: 0.4983 - val_accuracy: 0.4831\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 7s 101ms/step - loss: -5.4824 - accuracy: 0.6335 - val_loss: 0.5867 - val_accuracy: 0.4873\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 94ms/step - loss: -7.0429 - accuracy: 0.6532 - val_loss: 0.9162 - val_accuracy: 0.4768\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 6s 95ms/step - loss: -8.4939 - accuracy: 0.6682 - val_loss: 1.2951 - val_accuracy: 0.4873\n",
            "75/75 [==============================] - 4s 32ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 19s 185ms/step - loss: 0.5691 - accuracy: 0.2482 - val_loss: 0.4955 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 9s 127ms/step - loss: 0.5369 - accuracy: 0.2465 - val_loss: 0.4824 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 8s 121ms/step - loss: 0.5161 - accuracy: 0.2465 - val_loss: 0.4871 - val_accuracy: 0.2743\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 7s 108ms/step - loss: -1.3031 - accuracy: 0.4753 - val_loss: -0.2074 - val_accuracy: 0.4852\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 7s 103ms/step - loss: -5.2713 - accuracy: 0.6235 - val_loss: -0.8794 - val_accuracy: 0.4831\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 7s 110ms/step - loss: -7.4247 - accuracy: 0.6472 - val_loss: -0.8005 - val_accuracy: 0.4916\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 6s 91ms/step - loss: -9.2099 - accuracy: 0.6763 - val_loss: -1.5902 - val_accuracy: 0.4895\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 6s 95ms/step - loss: -10.7749 - accuracy: 0.6803 - val_loss: -1.5444 - val_accuracy: 0.4958\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 6s 95ms/step - loss: -11.8793 - accuracy: 0.6929 - val_loss: -1.6962 - val_accuracy: 0.4937\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 6s 96ms/step - loss: -13.2675 - accuracy: 0.6861 - val_loss: -0.9261 - val_accuracy: 0.4789\n",
            "74/74 [==============================] - 4s 31ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 25s 223ms/step - loss: 0.5456 - accuracy: 0.2604 - val_loss: 0.5785 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 12s 183ms/step - loss: 0.5282 - accuracy: 0.2602 - val_loss: 0.5797 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 11s 165ms/step - loss: 0.5073 - accuracy: 0.2602 - val_loss: 0.5342 - val_accuracy: 0.2384\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 11s 162ms/step - loss: -1.3944 - accuracy: 0.4977 - val_loss: -1.3368 - val_accuracy: 0.5274\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 10s 156ms/step - loss: -5.9118 - accuracy: 0.6387 - val_loss: -2.3691 - val_accuracy: 0.5211\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 10s 149ms/step - loss: -8.0773 - accuracy: 0.6722 - val_loss: -2.1777 - val_accuracy: 0.5253\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 10s 152ms/step - loss: -9.6075 - accuracy: 0.6835 - val_loss: -1.8627 - val_accuracy: 0.5380\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 10s 148ms/step - loss: -10.5487 - accuracy: 0.6821 - val_loss: -0.0049 - val_accuracy: 0.5042\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 10s 145ms/step - loss: -11.7482 - accuracy: 0.6893 - val_loss: -1.1552 - val_accuracy: 0.5190\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 10s 144ms/step - loss: -12.8079 - accuracy: 0.6903 - val_loss: -1.3563 - val_accuracy: 0.5253\n",
            "75/75 [==============================] - 7s 51ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 26s 231ms/step - loss: 0.5674 - accuracy: 0.2468 - val_loss: 0.4892 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 12s 176ms/step - loss: 0.5484 - accuracy: 0.2465 - val_loss: 0.4850 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 11s 164ms/step - loss: 0.5375 - accuracy: 0.2465 - val_loss: 0.4645 - val_accuracy: 0.2743\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 11s 161ms/step - loss: -1.4858 - accuracy: 0.4877 - val_loss: -1.3324 - val_accuracy: 0.4705\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 2.9045 - accuracy: 0.3695 - val_loss: 4.5897 - val_accuracy: 0.2764\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 10s 156ms/step - loss: 1.8301 - accuracy: 0.3071 - val_loss: 0.4108 - val_accuracy: 0.4177\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 10s 150ms/step - loss: -3.0813 - accuracy: 0.6327 - val_loss: -0.4306 - val_accuracy: 0.4789\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 10s 156ms/step - loss: -5.2503 - accuracy: 0.6427 - val_loss: 0.5727 - val_accuracy: 0.4831\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 10s 145ms/step - loss: -5.0229 - accuracy: 0.6420 - val_loss: -0.1281 - val_accuracy: 0.4789\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 10s 146ms/step - loss: -6.9506 - accuracy: 0.6092 - val_loss: 0.5192 - val_accuracy: 0.5021\n",
            "74/74 [==============================] - 7s 50ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 34s 314ms/step - loss: 0.5499 - accuracy: 0.2607 - val_loss: 0.5858 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 15s 218ms/step - loss: 0.5271 - accuracy: 0.2602 - val_loss: 0.5885 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 14s 208ms/step - loss: 0.4366 - accuracy: 0.2818 - val_loss: 0.2285 - val_accuracy: 0.4684\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 14s 216ms/step - loss: -2.9092 - accuracy: 0.5809 - val_loss: -0.9940 - val_accuracy: 0.4430\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 14s 202ms/step - loss: 3.5480 - accuracy: 0.3630 - val_loss: 7.1819 - val_accuracy: 0.2447\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 14s 207ms/step - loss: 1.7125 - accuracy: 0.3759 - val_loss: 0.1349 - val_accuracy: 0.4346\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 13s 201ms/step - loss: -2.3812 - accuracy: 0.5612 - val_loss: -0.6654 - val_accuracy: 0.4451\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 13s 198ms/step - loss: -4.8622 - accuracy: 0.6384 - val_loss: -0.2175 - val_accuracy: 0.4852\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 13s 196ms/step - loss: -6.5286 - accuracy: 0.6694 - val_loss: -0.3761 - val_accuracy: 0.3502\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 13s 198ms/step - loss: -6.7018 - accuracy: 0.6438 - val_loss: -1.3566 - val_accuracy: 0.5169\n",
            "75/75 [==============================] - 7s 67ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 36s 322ms/step - loss: 0.5742 - accuracy: 0.2479 - val_loss: 0.4973 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 15s 229ms/step - loss: 0.5442 - accuracy: 0.2465 - val_loss: 0.4836 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 15s 220ms/step - loss: 0.4193 - accuracy: 0.2803 - val_loss: 0.3375 - val_accuracy: 0.3692\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 14s 210ms/step - loss: -2.3572 - accuracy: 0.5663 - val_loss: 1.2184 - val_accuracy: 0.4135\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 14s 203ms/step - loss: -5.2692 - accuracy: 0.6064 - val_loss: -1.0875 - val_accuracy: 0.4810\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 13s 200ms/step - loss: -7.1111 - accuracy: 0.6446 - val_loss: -1.1656 - val_accuracy: 0.4873\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 13s 196ms/step - loss: -8.5599 - accuracy: 0.6610 - val_loss: -1.9578 - val_accuracy: 0.4304\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 13s 200ms/step - loss: -10.0213 - accuracy: 0.6749 - val_loss: -2.2697 - val_accuracy: 0.4789\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 13s 197ms/step - loss: -11.8841 - accuracy: 0.6875 - val_loss: -1.5446 - val_accuracy: 0.5105\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 13s 195ms/step - loss: -12.7514 - accuracy: 0.6878 - val_loss: -1.7867 - val_accuracy: 0.4831\n",
            "74/74 [==============================] - 8s 68ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 31s 333ms/step - loss: 0.5496 - accuracy: 0.2616 - val_loss: 0.5802 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 20s 294ms/step - loss: 0.5214 - accuracy: 0.2602 - val_loss: 0.6036 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 19s 282ms/step - loss: -0.0809 - accuracy: 0.3419 - val_loss: 1.1954 - val_accuracy: 0.4768\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 18s 274ms/step - loss: -3.7651 - accuracy: 0.5671 - val_loss: 5.0056 - val_accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 19s 280ms/step - loss: -4.7428 - accuracy: 0.5702 - val_loss: 4.4384 - val_accuracy: 0.4494\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 18s 275ms/step - loss: -0.8314 - accuracy: 0.4885 - val_loss: 0.3178 - val_accuracy: 0.4979\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 19s 283ms/step - loss: -9.8067 - accuracy: 0.6025 - val_loss: -3.1350 - val_accuracy: 0.4515\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 18s 269ms/step - loss: -12.9617 - accuracy: 0.6342 - val_loss: -0.6906 - val_accuracy: 0.5042\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 18s 265ms/step - loss: -15.0922 - accuracy: 0.6631 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 18s 264ms/step - loss: -17.0123 - accuracy: 0.6715 - val_loss: 0.3591 - val_accuracy: 0.5042\n",
            "75/75 [==============================] - 8s 89ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 28s 329ms/step - loss: 0.5645 - accuracy: 0.2475 - val_loss: 0.4975 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 20s 305ms/step - loss: 0.5394 - accuracy: 0.2465 - val_loss: 0.4803 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 19s 277ms/step - loss: 0.1877 - accuracy: 0.3500 - val_loss: 0.1580 - val_accuracy: 0.4768\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 19s 281ms/step - loss: -5.0637 - accuracy: 0.5700 - val_loss: 0.9858 - val_accuracy: 0.4578\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 18s 276ms/step - loss: -8.9369 - accuracy: 0.6176 - val_loss: -1.5531 - val_accuracy: 0.4599\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 18s 272ms/step - loss: -10.6621 - accuracy: 0.6134 - val_loss: -1.5318 - val_accuracy: 0.4747\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 19s 279ms/step - loss: -12.8360 - accuracy: 0.6266 - val_loss: -1.9705 - val_accuracy: 0.4810\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 18s 276ms/step - loss: -14.8122 - accuracy: 0.6397 - val_loss: -2.4024 - val_accuracy: 0.4726\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 18s 275ms/step - loss: -17.8185 - accuracy: 0.6547 - val_loss: -2.8111 - val_accuracy: 0.4599\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 18s 273ms/step - loss: -19.9148 - accuracy: 0.6662 - val_loss: -2.6787 - val_accuracy: 0.4620\n",
            "74/74 [==============================] - 8s 90ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 44s 510ms/step - loss: 0.5511 - accuracy: 0.2642 - val_loss: 0.6091 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 30s 453ms/step - loss: 0.5269 - accuracy: 0.2602 - val_loss: 0.5694 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 30s 449ms/step - loss: -0.1289 - accuracy: 0.3618 - val_loss: -0.3612 - val_accuracy: 0.3418\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 30s 448ms/step - loss: -5.5818 - accuracy: 0.5589 - val_loss: -2.1667 - val_accuracy: 0.4852\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 30s 443ms/step - loss: -10.0001 - accuracy: 0.6246 - val_loss: -2.3683 - val_accuracy: 0.5021\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 29s 437ms/step - loss: -12.7838 - accuracy: 0.6553 - val_loss: -3.4080 - val_accuracy: 0.4873\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 29s 439ms/step - loss: -13.8937 - accuracy: 0.6377 - val_loss: -4.5624 - val_accuracy: 0.5232\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 29s 437ms/step - loss: -16.5906 - accuracy: 0.6567 - val_loss: -1.6644 - val_accuracy: 0.5063\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 29s 437ms/step - loss: -17.8321 - accuracy: 0.6628 - val_loss: -1.7948 - val_accuracy: 0.4662\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 29s 435ms/step - loss: -20.3884 - accuracy: 0.6741 - val_loss: -5.0266 - val_accuracy: 0.5169\n",
            "75/75 [==============================] - 13s 145ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 44s 502ms/step - loss: 0.5576 - accuracy: 0.2479 - val_loss: 0.5032 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 31s 456ms/step - loss: 0.5382 - accuracy: 0.2465 - val_loss: 0.4622 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 30s 443ms/step - loss: -0.8589 - accuracy: 0.4011 - val_loss: -1.6542 - val_accuracy: 0.4430\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 30s 441ms/step - loss: -6.5307 - accuracy: 0.5513 - val_loss: -2.4891 - val_accuracy: 0.5084\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 29s 440ms/step - loss: -9.7195 - accuracy: 0.6172 - val_loss: -2.0517 - val_accuracy: 0.4789\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 30s 442ms/step - loss: -12.1125 - accuracy: 0.6416 - val_loss: -2.4504 - val_accuracy: 0.4852\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 29s 434ms/step - loss: -3.1666 - accuracy: 0.5154 - val_loss: 11.8270 - val_accuracy: 0.3038\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 29s 438ms/step - loss: 1.1466 - accuracy: 0.4321 - val_loss: 0.4629 - val_accuracy: 0.4937\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 29s 432ms/step - loss: -8.0674 - accuracy: 0.6528 - val_loss: 3.3059 - val_accuracy: 0.4726\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 29s 435ms/step - loss: -16.2491 - accuracy: 0.6582 - val_loss: -3.7728 - val_accuracy: 0.4937\n",
            "74/74 [==============================] - 13s 145ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 60s 679ms/step - loss: 0.5490 - accuracy: 0.2614 - val_loss: 0.5800 - val_accuracy: 0.2384\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 42s 619ms/step - loss: 0.5253 - accuracy: 0.2602 - val_loss: 0.6391 - val_accuracy: 0.2384\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 42s 623ms/step - loss: -0.1447 - accuracy: 0.3979 - val_loss: 3.2714 - val_accuracy: 0.3692\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 42s 626ms/step - loss: -5.4161 - accuracy: 0.5791 - val_loss: 1.4805 - val_accuracy: 0.4304\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 42s 625ms/step - loss: -8.9567 - accuracy: 0.5992 - val_loss: -1.0519 - val_accuracy: 0.4726\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 41s 610ms/step - loss: -11.5995 - accuracy: 0.6471 - val_loss: -1.6610 - val_accuracy: 0.4979\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 40s 602ms/step - loss: -14.2779 - accuracy: 0.6610 - val_loss: -1.9575 - val_accuracy: 0.4768\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 40s 603ms/step - loss: -16.8987 - accuracy: 0.6734 - val_loss: -1.0638 - val_accuracy: 0.5148\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 40s 601ms/step - loss: -18.0441 - accuracy: 0.6509 - val_loss: -0.1599 - val_accuracy: 0.4367\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 42s 622ms/step - loss: -20.6816 - accuracy: 0.6755 - val_loss: -2.5144 - val_accuracy: 0.4831\n",
            "75/75 [==============================] - 18s 201ms/step\n",
            "Epoch 1/10\n",
            "67/67 [==============================] - 61s 695ms/step - loss: 0.5551 - accuracy: 0.2482 - val_loss: 0.4869 - val_accuracy: 0.2743\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 42s 625ms/step - loss: 0.5383 - accuracy: 0.2465 - val_loss: 0.4294 - val_accuracy: 0.2743\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 43s 637ms/step - loss: 0.1678 - accuracy: 0.4025 - val_loss: 5.6239 - val_accuracy: 0.3059\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 41s 612ms/step - loss: 3.4168 - accuracy: 0.3448 - val_loss: 0.9095 - val_accuracy: 0.3228\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 42s 625ms/step - loss: -1.1822 - accuracy: 0.5264 - val_loss: 0.7147 - val_accuracy: 0.4494\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 41s 609ms/step - loss: -0.4431 - accuracy: 0.4715 - val_loss: 0.5167 - val_accuracy: 0.4135\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 42s 628ms/step - loss: -4.5714 - accuracy: 0.5158 - val_loss: -1.7809 - val_accuracy: 0.3650\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 41s 610ms/step - loss: -8.1312 - accuracy: 0.5506 - val_loss: -1.7031 - val_accuracy: 0.4599\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 41s 609ms/step - loss: -9.5595 - accuracy: 0.5480 - val_loss: -1.2066 - val_accuracy: 0.4536\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 42s 621ms/step - loss: -9.7205 - accuracy: 0.4518 - val_loss: -1.9755 - val_accuracy: 0.4705\n",
            "74/74 [==============================] - 17s 200ms/step\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 25s 127ms/step - loss: 0.5483 - accuracy: 0.2574 - val_loss: 0.5789 - val_accuracy: 0.2468\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 8s 58ms/step - loss: 0.5256 - accuracy: 0.2544 - val_loss: 0.5545 - val_accuracy: 0.2468\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 8s 63ms/step - loss: -0.1656 - accuracy: 0.3900 - val_loss: -0.6338 - val_accuracy: 0.5243\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 8s 57ms/step - loss: -3.3279 - accuracy: 0.6006 - val_loss: -1.2319 - val_accuracy: 0.5137\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 7s 51ms/step - loss: -5.1728 - accuracy: 0.6357 - val_loss: -1.3959 - val_accuracy: 0.5042\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 7s 50ms/step - loss: -6.7605 - accuracy: 0.6541 - val_loss: -2.0051 - val_accuracy: 0.5243\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 7s 49ms/step - loss: -7.9560 - accuracy: 0.6689 - val_loss: -1.7010 - val_accuracy: 0.5095\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 7s 49ms/step - loss: -9.1037 - accuracy: 0.6762 - val_loss: -2.6796 - val_accuracy: 0.5327\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 7s 50ms/step - loss: -10.0547 - accuracy: 0.6822 - val_loss: -2.3358 - val_accuracy: 0.5369\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 7s 49ms/step - loss: -10.8689 - accuracy: 0.6788 - val_loss: -3.1545 - val_accuracy: 0.5316\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[(&#x27;rnn&#x27;,\n",
              "                                        SentimentRNNWrapper(n_words=16477))]),\n",
              "             param_grid={&#x27;rnn__learning_rate&#x27;: [0.001, 0.0001],\n",
              "                         &#x27;rnn__lstm_size&#x27;: [128, 256, 512],\n",
              "                         &#x27;rnn__num_layers&#x27;: [1, 2, 3]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[(&#x27;rnn&#x27;,\n",
              "                                        SentimentRNNWrapper(n_words=16477))]),\n",
              "             param_grid={&#x27;rnn__learning_rate&#x27;: [0.001, 0.0001],\n",
              "                         &#x27;rnn__lstm_size&#x27;: [128, 256, 512],\n",
              "                         &#x27;rnn__num_layers&#x27;: [1, 2, 3]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;rnn&#x27;, SentimentRNNWrapper(n_words=16477))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SentimentRNNWrapper</label><div class=\"sk-toggleable__content\"><pre>SentimentRNNWrapper(n_words=16477)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[('rnn',\n",
              "                                        SentimentRNNWrapper(n_words=16477))]),\n",
              "             param_grid={'rnn__learning_rate': [0.001, 0.0001],\n",
              "                         'rnn__lstm_size': [128, 256, 512],\n",
              "                         'rnn__num_layers': [1, 2, 3]},\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e23KiurDXC55",
        "outputId": "35263aac-d083-4840-ef73-e1c83c770f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found:  {'rnn__learning_rate': 0.0001, 'rnn__lstm_size': 128, 'rnn__num_layers': 1}\n",
            "Best cross-validation score: 0.52\n"
          ]
        }
      ],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usb3dmsrXC55"
      },
      "source": [
        "# Test Model\n",
        "Now it's time to test the best model combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "G_3CW3vVXC56"
      },
      "outputs": [],
      "source": [
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UcEmUpWXC56",
        "outputId": "a96a9d49-4342-4288-eae0-874713b46520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 2s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p2S6zmuXC56",
        "outputId": "d28ab606-1d65-44f9-f977-449cdf4ff288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 39.13%\n"
          ]
        }
      ],
      "source": [
        "best_accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Test accuracy: {best_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQEG0R0ZXC56"
      },
      "source": [
        "# Conclusion\n",
        "In this project, I developed a Sentiment Analysis model using a Recurrent Neural Network (RNN) architecture implemented with TensorFlow and Keras. The goal was to classify the sentiment of text data into positive or negative categories. Heres a summary of my approach and findings:\n",
        "\n",
        "1. **Results**: The best model achieved a test **accuracy of 39.13%**, which fell short of my expectations. This outcome may be attributed to over-processing the data and the dataset itself. Given that the original text sequences were not particularly long, each adjustment and preprocessing step reduced the amount of usable data, potentially compromising the model's performance and its ability to capture features. The data was heavily skewed towards positive and neutral sentiments, so having a more even exposure would give the model less bias from negative sentiment. I also believe that if I had more compute power, the pipeline would have produced a winning model (80% and above) between thet 5 hyperparameters.\n",
        "\n",
        "2. **Model Architecture**: RNN with LSTM layers are well-suited for sequential data like text due to their ability to capture dependencies over time. The model included embedding layers for text representation, multiple LSTM layers for learning hierarchical features, and dropout layers for regularization.\n",
        "\n",
        "3. **Hyperparameter Tuning**: I utilized GridSearchCV to systematically search through different combinations of hyperparameters such as sequence length (`seq_len`), LSTM size (`lstm_size`), number of layers (`num_layers`), batch size (`batch_size`), and learning rate (`learning_rate`).  The goal was to optimize model performance by finding the best configuration for these parameters. The best model had a `learning_rate` of 0.0001, a `lstm_size` of 128, and `num_layers` of 1.\n",
        "\n",
        "4. **Training and Evaluation**: I evaluated the models performance using metrics like accuracy to measure its ability to correctly predict sentiment labels on unseen data.\n",
        "\n",
        "5. **Performance**: Through iterative tuning and evaluation, I observed improvements in the models accuracy as I optimized hyperparameters. This process allowed us to fine-tune the model to achieve better performance in sentiment classification tasks.\n",
        "\n",
        "6. **Challenges and Considerations**: During the project, I encountered challenges such as balancing model complexity with computational resources and managing overfitting. Regularization techniques like dropout and careful selection of hyperparameters were crucial in addressing these challenges. Maybe adding a batch normalizer would have enhanced the performance. \n",
        "\n",
        "7. **Future Directions**: Moving forward, further enhancements could include exploring more advanced RNN variants (e.g., GRU, bi-directional LSTM), incorporating pre-trained word embeddings (e.g., Word2Vec, GloVe), or leveraging transfer learning techniques from larger language models (e.g., BERT, GPT). Additionally, expanding the dataset size and diversity could help generalize the models ability to handle different types of sentiment analysis tasks and domains.\n",
        "\n",
        "In conclusion, this project demonstrated the effectiveness of RNN-based architectures for sentiment analysis tasks and highlighted the importance of hyperparameter tuning in optimizing model performance. By continually refining and expanding upon these techniques, I can advance the state-of-the-art in natural language processing applications, particularly in sentiment analysis and related domains."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
