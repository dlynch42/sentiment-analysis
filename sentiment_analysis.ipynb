{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTa4Q_raXC5z"
      },
      "source": [
        "# Stock Market News Sentiment\n",
        "This project looks into classifying the sentiment of stock market news and tweets into a bullish, bearish, or neutral outlook. \n",
        "\n",
        "The data is a concatenation from [Kaggle: Stock-Market Sentiment Dataset](https://www.kaggle.com/datasets/yash612/stockmarket-sentiment-dataset) and [Kaggle: Financial Sentiment Analysis](https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis). The data was combined in [data_extraction.ipynb](data_extraction.ipynb)\n",
        "\n",
        "The data is broken up into two columns: `Text` that is a block of text and `Sentiment` that is a value between -1 and 1 value, meaning -1 is negative sentiment, 0 is neutral, and 1 is positive sentiment.\n",
        "\n",
        "A model such as this can be applied to many areas outside of finance such as marketing, politics, or product feedback. It could also be combined with other algorithms to create a multi-modal approach for a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9IBlY5UXC50"
      },
      "source": [
        "# Set up\n",
        "Import the necessary dependencies and load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9YpRSl-GXM-U"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install seaborn\n",
        "# !pip install scikit-learn\n",
        "# !pip install nltk\n",
        "# !pip install pyprind\n",
        "# !pip install tensorflow\n",
        "# !pip install keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lI9ltICoXC50"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "import pyprind\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import RNN, Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mZA0ihP1DjO",
        "outputId": "564f3394-deac-493c-a89e-c52c8535d086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: \n",
            "Running on a TPU w/8 cores\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(f'Running on a TPU w/{tpu.num_accelerators()[\"TPU\"]} cores')\n",
        "except:\n",
        "        if tf.config.list_physical_devices('GPU'):\n",
        "            strategy = tf.distribute.MirroredStrategy()\n",
        "            print(\"Running on GPU.\")\n",
        "        else:\n",
        "            strategy = tf.distribute.get_strategy()\n",
        "            print(\"Running on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NazWEKZWXC51"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLJXCYmZXC51"
      },
      "source": [
        "# EDA & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLkvBp5DXC51"
      },
      "source": [
        "## EDA\n",
        "After exploring the data, here are some key findings that will help in our preprocessing and feature extraction:\n",
        "- There are 16479 records, with 11842 being unique.\n",
        "- The max words are 81 while the minimum words are 2. The average amount of words are just over 19.\n",
        "- The sentiment count for each value is '1' at 6900, '0' at 6009, and '-1' at 3570, which makes me believe that the model might have some skew away from negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ean9OE4SXC52",
        "outputId": "43b53d1a-dbfe-41d6-f546-c5b7752244f5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 16479,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11842,\n        \"samples\": [\n          \"ALEXANDRIA , Va. , June 7 -- Michael G. Williams of Newbury Park , Calif. , has developed a network device .\",\n          \"When is Demark coming back to prop up AAP?  Yesterday a classic dead cat bounce.   Now a value stock, need go lower to find size buyers.\",\n          \"AXTI eleased news. Watching if this can go into 3s today  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a0f858c8-8569-4f83-8161-987f528157e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MNTA Over 12.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OI  Over 21.37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0f858c8-8569-4f83-8161-987f528157e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0f858c8-8569-4f83-8161-987f528157e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0f858c8-8569-4f83-8161-987f528157e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25efe0ae-b80f-4931-aa73-5742eb9eb656\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25efe0ae-b80f-4931-aa73-5742eb9eb656')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25efe0ae-b80f-4931-aa73-5742eb9eb656 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                Text  Sentiment\n",
              "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
              "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
              "2  user I'd be afraid to short AMZN - they are lo...          1\n",
              "3                                  MNTA Over 12.00            1\n",
              "4                                   OI  Over 21.37            1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3JVWBwmXC52",
        "outputId": "2b5b97f4-5f9e-43c0-a9a9-bc0eaaef6d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16479 entries, 0 to 16478\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Text       16479 non-null  object\n",
            " 1   Sentiment  16479 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 257.6+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "J2HnbDhoXC52",
        "outputId": "8dce1f3f-3cdf-4fd0-893b-6e32bcf2bb26"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5826.1067022254565,\n        \"min\": -1.0,\n        \"max\": 16479.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          16479.0,\n          0.2020753686510104,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-56abe6b0-2361-4a7d-89f4-789f21439916\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16479.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.202075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.771074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56abe6b0-2361-4a7d-89f4-789f21439916')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56abe6b0-2361-4a7d-89f4-789f21439916 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56abe6b0-2361-4a7d-89f4-789f21439916');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a69991bc-7366-4182-be95-3540f512e53b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a69991bc-7366-4182-be95-3540f512e53b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a69991bc-7366-4182-be95-3540f512e53b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Sentiment\n",
              "count  16479.000000\n",
              "mean       0.202075\n",
              "std        0.771074\n",
              "min       -1.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpryPsS6XC52",
        "outputId": "141adc03-c76f-499d-9627-7128a565f482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text         11842\n",
              "Sentiment        3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5j7IjmXC52",
        "outputId": "72b85c30-76f5-4376-c080-23e02b56d493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max words: 81\n",
            "Min words: 2,\n",
            "Avg words: 19.162752594210815\n"
          ]
        }
      ],
      "source": [
        "data['Num_Words'] = data['Text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "max_words = data['Num_Words'].max()\n",
        "min_words = data['Num_Words'].min()\n",
        "avg_words = data['Num_Words'].mean()\n",
        "\n",
        "print(f\"Max words: {max_words}\\nMin words: {min_words},\\nAvg words: {avg_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taTJmkXZXC52",
        "outputId": "c7315d85-0ca1-4bdb-9474-01570989b024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment\n",
              " 1    6900\n",
              " 0    6009\n",
              "-1    3570\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_counts = data['Sentiment'].value_counts()\n",
        "sentiment_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "vk0bw6uNXC53",
        "outputId": "c1252290-25bb-4c48-bc6a-c9645b2f1550"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Sentiment', data=data)\n",
        "plt.title('Distribution of Labels in Training Set')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "9zqr1NJzXC53",
        "outputId": "b90b945d-0a64-4955-ef11-1b3c3e1c7ba8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "avg_words_per_category = data.groupby('Sentiment')['Num_Words'].mean()\n",
        "\n",
        "avg_words_per_category.plot(kind='bar')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Average Number of Words')\n",
        "plt.title('Average Words per Sentiment')\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y3fzAxPXC53"
      },
      "source": [
        "## Preprocessing\n",
        "We need to preprocess the data to make it readable for the model.\n",
        "\n",
        "**Steps**:\n",
        "1. We need to drop all duplicates\n",
        "\n",
        "2. We need to remove all the stop words in the text using `nltk`'s stopwords.\n",
        "\n",
        "3. We need to remove HTML tags, URLs, special characters, and convert to lowercase.\n",
        "\n",
        "4. We need to find unique words in dataset (using `Counter()`) to count each word's occurence and convert text to integers. Then we will create a mapping to map each unique word to integer.\n",
        "\n",
        "5. We need to make the sequences same length. The sequences that don't meet that length will be padded with '0's' while the longer ones will be cut. We will define same-length sequences by:\n",
        "    - If sequence length < 200: left-pad with zeros\n",
        "    - If sequence length > 200: use the last 200 elements\n",
        "\n",
        "6. Use `train_test_split` to get an 80/20 split of the data\n",
        "\n",
        "7. Apply one-hot encoding to represent the categorical labels (`y`) as binary vectors\n",
        "    - For three classes it would be represented as `[1, 0, 0]`, `[0, 1, 0]`, or `[0, 0, 1]`\n",
        "    - Doing this after splitting so that we can use in `GridSearchCV`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MipyD_9eXC53"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates(subset=['Text'], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVj1dT9aXC53",
        "outputId": "b93aff67-b0e1-48a7-d1a7-b67228cfebf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffj9GEgTXC53",
        "outputId": "b8508614-76d1-4920-db23-ebc2949250ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-223b7f316d23>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n"
          ]
        }
      ],
      "source": [
        "data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejNJDbyjXC54",
        "outputId": "9aa8ce87-9816-421c-b71d-85b3d15339b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-8d68b9c87597>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Text'] = data['Text'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
            "<ipython-input-16-8d68b9c87597>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Text'] = data['Text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
            "<ipython-input-16-8d68b9c87597>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
            "<ipython-input-16-8d68b9c87597>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Text'] = data['Text'].apply(lambda x: x.lower())\n"
          ]
        }
      ],
      "source": [
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
        "data['Text'] = data['Text'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6Mwq-1XC54",
        "outputId": "50d42724-03f8-48ff-d3a1-ab0a8e9e838c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Counting words occurences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n",
            "Map sentiments to ints\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eur', 's', 'company', 'aap', 'user']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ]
        }
      ],
      "source": [
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(data['Text']),\n",
        "                       title='Counting words occurences')\n",
        "for i, sentiment in enumerate(data['Text']):\n",
        "    text = ''.join([c if c not in punctuation else ' '+c+' ' for c in sentiment]).lower()\n",
        "    data.loc[i,'Text'] = text\n",
        "    pbar.update()\n",
        "    counts.update(text.split())\n",
        "\n",
        "\n",
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "print(word_counts[:5])\n",
        "word_to_int = {word: ii for ii, word in enumerate(word_counts, 1)}\n",
        "\n",
        "mapped_sentiment = []\n",
        "pbar = pyprind.ProgBar(len(data['Text']),\n",
        "                       title='Map sentiments to ints')\n",
        "for sentiment in data['Text']:\n",
        "    mapped_sentiment.append([word_to_int[word] for word in sentiment.split()])\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6657k-P6XC54"
      },
      "outputs": [],
      "source": [
        "sequence_length = 200\n",
        "sequences = np.zeros((len(mapped_sentiment), sequence_length), dtype=int)\n",
        "for i, row in enumerate(mapped_sentiment):\n",
        "    if row: # Check if the row is not empty\n",
        "        sentiment_arr = np.array(row)\n",
        "        sequences[i, -len(row):] = sentiment_arr[-sequence_length:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HLF7urkhXC54"
      },
      "outputs": [],
      "source": [
        "X = sequences\n",
        "y = data['Sentiment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_oh = to_categorical(y_train, num_classes=3)\n",
        "y_test_oh = to_categorical(y_test, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vWtIT1mhXC54"
      },
      "outputs": [],
      "source": [
        "assert (X_train.shape == (9473, 200) )\n",
        "assert (X_test.shape == (2369, 200) )\n",
        "assert (y_train.shape == (9473, ) )\n",
        "assert (y_test.shape == (2369, ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PrPOYMrRcBx5"
      },
      "outputs": [],
      "source": [
        "assert (y_train_oh.shape == (9473, 3) )\n",
        "assert (y_test_oh.shape == (2369, 3) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPn66AytXC55"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "The `SentimentRNN` class implements a recurrent neural network (RNN) for sentiment analysis using TensorFlow and Keras. It utilizes an **embedding layer** followed by **LSTM** (Long Short-Term Memory) layers with bidirectional processing to capture sequential dependencies effectively. Dropout regularization is applied to mitigate overfitting, and the final output layer uses a sigmoid activation function for binary classification. This architecture leverages the strengths of LSTM networks for handling sequential data and is suitable for tasks like sentiment analysis where understanding the context and dependencies among words is crucial for accurate classification:\n",
        "\n",
        "**Embedding Layer:**\n",
        "  - **Input:**\n",
        "    - Dimension of the vocabulary (`n_words`)\n",
        "    - Input sequence length (`seq_len`)\n",
        "  - **Functionality:**\n",
        "    - Maps each word index to a dense vector representation (`embed_size`)\n",
        "   \n",
        "**LSTM Layers:**\n",
        "  - **Bidirectional LSTM:**\n",
        "    - **Units:** `lstm_size`\n",
        "    - **Number of Layers:** `num_layers`\n",
        "    - **Return Sequences:** True for all layers except the last one\n",
        "    - **Functionality:**\n",
        "      - Captures forward and backward context of the input sequences\n",
        "      - Helps in understanding context from both past and future states\n",
        "\n",
        "**Dropout Layers:**\n",
        "  - **Usage:**\n",
        "    - Applied after each LSTM layer (`Dropout(0.5)`)\n",
        "    - Reduces overfitting by randomly setting a fraction of inputs to zero during training\n",
        "   \n",
        "**Dense Output Layer:**\n",
        "  - **Units:** 3 (for the three classes: -1, 0, and 1)\n",
        "  - **Activation:** softmax\n",
        "  - **Functionality:**\n",
        "    - Outputs three probability scores for multi-class sentiment classification (one for each class: -1, 0, and 1).\n",
        "\n",
        "**Optimizer and Loss Function:**\n",
        "  - **Optimizer:** Adam with a learning rate (`learning_rate`)\n",
        "  - **Loss Function:** Binary Cross-Entropy\n",
        "  - **Metrics:** Accuracy for evaluation during training\n",
        "   \n",
        "**Training:**\n",
        "  - Input: `X_train` (numpy array of shape `(num_samples, seq_len)`)\n",
        "  - Labels: `y_train` (numpy array of shape `(num_samples,)`)\n",
        "  - Trains the model using `num_epochs` with a batch size of `batch_size`\n",
        "  - Validates on 10% of the training data (`validation_split=0.1`)\n",
        "\n",
        "**Prediction:**\n",
        "  - Input: `X_data` (numpy array of shape `(num_samples, seq_len)`)\n",
        "  - Returns either predicted labels (`numpy.ndarray` of integers) or probabilities (`numpy.ndarray` of floats) based on the `return_proba` parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pJfcYKE23NQf"
      },
      "outputs": [],
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zmXxUnXdXC55"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN:\n",
        "    \"\"\"\n",
        "    A Recurrent Neural Network model for sentiment analysis using TensorFlow and Keras.\n",
        "\n",
        "    Methods:\n",
        "        build_model():\n",
        "            Builds the RNN model using TensorFlow and Keras.\n",
        "\n",
        "        train(X_train, y_train, num_epochs):\n",
        "            Trains the RNN model on the provided training data.\n",
        "\n",
        "        predict(X_data, return_proba=False):\n",
        "            Makes predictions on new data.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_words, seq_len=200,\n",
        "                 lstm_size=256, num_layers=1, batch_size=64,\n",
        "                 learning_rate=0.0001, embed_size=200):\n",
        "        \"\"\"\n",
        "        Initializes the SentimentRNN object with specified parameters.\n",
        "\n",
        "        Args:\n",
        "            n_words (int): Number of words in the vocabulary.\n",
        "            seq_len (int, optional): Length of input sequences (default is 200).\n",
        "            lstm_size (int, optional): Size of LSTM units (default is 256).\n",
        "            num_layers (int, optional): Number of LSTM layers (default is 1).\n",
        "            batch_size (int, optional): Batch size for training (default is 64).\n",
        "            learning_rate (float, optional): Learning rate for the optimizer (default is 0.0001).\n",
        "            embed_size (int, optional): Size of word embeddings (default is 200).\n",
        "        \"\"\"\n",
        "        self.n_words = n_words\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size # * tpu_strategy.num_replicas_in_sync\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the LSTM-based sentiment analysis model using tf.keras.Sequential.\n",
        "        Embedding layer, LSTM layers (with dropout), and Dense output layer are added.\n",
        "        Adam optimizer is used with binary cross-entropy loss.\n",
        "        \"\"\"\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(input_dim=self.n_words, output_dim=self.embed_size, input_length=self.seq_len))\n",
        "        for _ in range(self.num_layers):\n",
        "            self.model.add(Bidirectional(LSTM(self.lstm_size, return_sequences=True)))\n",
        "            self.model.add(Dropout(0.5))\n",
        "        self.model.add(Bidirectional(LSTM(self.lstm_size)))\n",
        "        self.model.add(Dropout(0.5))\n",
        "        self.model.add(Dense(3, activation='softmax'))  # Three neurons with softmax activation for multi-class classification\n",
        "\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "        # self.model.summary()\n",
        "\n",
        "    def train(self, X_train, y_train, num_epochs):\n",
        "        \"\"\"\n",
        "        Trains the sentiment analysis model on the provided training data.\n",
        "\n",
        "        Args:\n",
        "            X_train (numpy.ndarray): Training input data of shape (num_samples, seq_len).\n",
        "            y_train (numpy.ndarray): Training labels of shape (num_samples,).\n",
        "            num_epochs (int): Number of epochs to train the model.\n",
        "        \"\"\"\n",
        "        self.model.fit(X_train, y_train, epochs=num_epochs, batch_size=self.batch_size, validation_split=0.1)\n",
        "\n",
        "    def predict(self, X_data, return_proba=False):\n",
        "        \"\"\"\n",
        "        Predicts sentiment labels or probabilities for input data.\n",
        "\n",
        "        Args:\n",
        "            X_data (numpy.ndarray): Input data of shape (num_samples, seq_len).\n",
        "            return_proba (bool, optional): If True, returns predicted probabilities; otherwise, returns labels (default is False).\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted labels (if return_proba=False) or probabilities (if return_proba=True).\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(X_data, batch_size=self.batch_size)\n",
        "        if return_proba:\n",
        "            return predictions\n",
        "        else:\n",
        "            return np.argmax(predictions, axis=1)  # Return the class with the highest probability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**n_words**: Check the maximum index value in X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mm0UyTDpXC55"
      },
      "outputs": [],
      "source": [
        "with tpu_strategy.scope():\n",
        "  n_words = max(list(word_to_int.values())) + 1\n",
        "  rnn = SentimentRNN(n_words=n_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_PBsdcWXC55"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxyxYLNzXC55",
        "outputId": "bbef823a-2c9d-4bd9-a7e5-98a61794a374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 40s 199ms/step - loss: 1.0444 - accuracy: 0.4808 - val_loss: 1.0049 - val_accuracy: 0.5084\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.8721 - accuracy: 0.5866 - val_loss: 0.7927 - val_accuracy: 0.6319\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.7038 - accuracy: 0.6618 - val_loss: 0.7669 - val_accuracy: 0.6540\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.5603 - accuracy: 0.7469 - val_loss: 0.7883 - val_accuracy: 0.6920\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.3782 - accuracy: 0.8570 - val_loss: 0.8159 - val_accuracy: 0.7120\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.2452 - accuracy: 0.9116 - val_loss: 0.8768 - val_accuracy: 0.7099\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.1674 - accuracy: 0.9429 - val_loss: 1.0143 - val_accuracy: 0.6994\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.1271 - accuracy: 0.9604 - val_loss: 1.0790 - val_accuracy: 0.6951\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.0914 - accuracy: 0.9730 - val_loss: 1.1536 - val_accuracy: 0.6930\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 16s 118ms/step - loss: 0.0738 - accuracy: 0.9799 - val_loss: 1.2744 - val_accuracy: 0.7004\n"
          ]
        }
      ],
      "source": [
        "rnn.train(X_train, y_train_oh, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVH3X0wTXC55",
        "outputId": "b4dbfcfc-8930-492f-9084-4eff55e730e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 5s 50ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = rnn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJNu_40DXC55",
        "outputId": "86c8fb7e-4a30-435d-82eb-08360a8752b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 73.03%\n"
          ]
        }
      ],
      "source": [
        "accuracy = np.mean(preds == np.argmax(y_test_oh, axis=1))\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJA-ScnXC55"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "Let's see if we can increase the accuracy of this model. We will use GridSearch, but first, we need to create a wrapper for our model in order to use it.\n",
        "\n",
        "We will be working on the following hyperparameters:\n",
        "- `seq_len`: Affects how much contextual information the model can capture from each input text\n",
        "- `lstm_size`: Directly impacts the model's capacity to learn complex patterns and dependencies within the data\n",
        "- `num_layers`: Allows the model to learn hierarchical representations of text data, potentially improving its ability to understand nuanced sentiment expressions\n",
        "- `batch_size`: Affects the gradient update dynamics and training stability\n",
        "- `learning_rate`: Controls how much to update the model in response to estimated gradients\n",
        "\n",
        "In consideration of run time, I chose to focus on `lstm_size`, `num_layers`, and `learning_rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Sf5c6c0hXC55"
      },
      "outputs": [],
      "source": [
        "class SentimentRNNWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_words, seq_len=200, lstm_size=256, num_layers=1,\n",
        "                 batch_size=64, learning_rate=0.0001, embed_size=200):\n",
        "        self.n_words = n_words\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, num_epochs=10):\n",
        "        \"\"\"Fit method for GridSearchCV compatibility.\n",
        "\n",
        "        Args:\n",
        "            X: X training data\n",
        "            y: y training data\n",
        "            num_epochs (int, optional): _description_. Defaults to 10.\n",
        "\n",
        "        Returns:\n",
        "            _type_: _description_\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, estimator=self, dtype=None)\n",
        "        y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
        "\n",
        "        self.model = SentimentRNN(\n",
        "            n_words=self.n_words,\n",
        "            seq_len=self.seq_len,\n",
        "            lstm_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            batch_size=self.batch_size,\n",
        "            learning_rate=self.learning_rate,\n",
        "            embed_size=self.embed_size\n",
        "        )\n",
        "\n",
        "        self.model.train(X, y, num_epochs=num_epochs)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict method for GridSearchCV compatibility\n",
        "\n",
        "        Args:\n",
        "            X: Assumes X is the test data\n",
        "\n",
        "        Returns:\n",
        "            predictions: Predictions made by the model\n",
        "        \"\"\"\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"Get parameters for the estimator. This is for GridSearchCV compatibility.\n",
        "\n",
        "        Args:\n",
        "            deep (bool, optional): Controls the depth of the attributes that are included in the returned dictionary of parameters. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            params: Dictionary of parameters\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'n_words': self.n_words,\n",
        "            'seq_len': self.seq_len,\n",
        "            'lstm_size': self.lstm_size,\n",
        "            'num_layers': self.num_layers,\n",
        "            'batch_size': self.batch_size,\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'embed_size': self.embed_size\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        \"\"\"Set the parameters of the estimator. This is for GridSearchCV compatibility.\n",
        "\n",
        "        Returns:\n",
        "            params: Sets the dictionary of parameters\n",
        "        \"\"\"\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5pgBfQ0xXC55"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('rnn', SentimentRNNWrapper(n_words=n_words)),\n",
        "])\n",
        "\n",
        "# Define parameters for grid search\n",
        "parameters = {\n",
        "    # 'rnn__seq_len': [100, 200, 300],\n",
        "    'rnn__lstm_size': [128, 256, 512],\n",
        "    'rnn__num_layers': [1, 2, 3],\n",
        "    # 'rnn__batch_size': [32, 64, 128],\n",
        "    'rnn__learning_rate': [0.001, 0.0001],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dz6eZ_vQXC55"
      },
      "outputs": [],
      "source": [
        "with tpu_strategy.scope():\n",
        "  grid_search = GridSearchCV(pipeline, parameters, cv=3, verbose=1, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfGhiFNGXC55",
        "outputId": "42fb4bcb-9e77-44a2-ab38-4adc84a61806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 28s 188ms/step - loss: 0.9229 - accuracy: 0.5455 - val_loss: 0.7455 - val_accuracy: 0.6741\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.4918 - accuracy: 0.8015 - val_loss: 0.6639 - val_accuracy: 0.7389\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.1979 - accuracy: 0.9296 - val_loss: 0.8172 - val_accuracy: 0.7168\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.1045 - accuracy: 0.9671 - val_loss: 0.9284 - val_accuracy: 0.7294\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0653 - accuracy: 0.9821 - val_loss: 1.0641 - val_accuracy: 0.7073\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 1.1614 - val_accuracy: 0.6946\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0425 - accuracy: 0.9880 - val_loss: 1.1903 - val_accuracy: 0.7247\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 1.4567 - val_accuracy: 0.6994\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 1.2949 - val_accuracy: 0.6994\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 1.5811 - val_accuracy: 0.6883\n",
            "50/50 [==============================] - 5s 37ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 29s 189ms/step - loss: 0.9274 - accuracy: 0.5511 - val_loss: 0.7421 - val_accuracy: 0.6535\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.5105 - accuracy: 0.7901 - val_loss: 0.6989 - val_accuracy: 0.7326\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1925 - accuracy: 0.9344 - val_loss: 0.8891 - val_accuracy: 0.7041\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0991 - accuracy: 0.9683 - val_loss: 1.1093 - val_accuracy: 0.7009\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 1.3660 - val_accuracy: 0.6835\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 1.3308 - val_accuracy: 0.7025\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 1.3358 - val_accuracy: 0.7073\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 1.5622 - val_accuracy: 0.6867\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 1.5762 - val_accuracy: 0.6709\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 1.5371 - val_accuracy: 0.6899\n",
            "50/50 [==============================] - 5s 38ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 29s 195ms/step - loss: 0.9093 - accuracy: 0.5586 - val_loss: 0.7794 - val_accuracy: 0.6218\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.5232 - accuracy: 0.7813 - val_loss: 0.7405 - val_accuracy: 0.7104\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.2216 - accuracy: 0.9258 - val_loss: 0.8361 - val_accuracy: 0.7009\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.1140 - accuracy: 0.9643 - val_loss: 1.0866 - val_accuracy: 0.6741\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.0677 - accuracy: 0.9803 - val_loss: 1.3161 - val_accuracy: 0.6677\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 1.4379 - val_accuracy: 0.6883\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 1.4451 - val_accuracy: 0.6551\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 1.3806 - val_accuracy: 0.6725\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 1.5683 - val_accuracy: 0.6804\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 1.6551 - val_accuracy: 0.6725\n",
            "50/50 [==============================] - 5s 38ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 42s 282ms/step - loss: 0.9211 - accuracy: 0.5488 - val_loss: 0.7763 - val_accuracy: 0.6234\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.5538 - accuracy: 0.7632 - val_loss: 0.7206 - val_accuracy: 0.7199\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2485 - accuracy: 0.9147 - val_loss: 0.7733 - val_accuracy: 0.6851\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1278 - accuracy: 0.9611 - val_loss: 0.9451 - val_accuracy: 0.7120\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 0.0832 - accuracy: 0.9755 - val_loss: 1.1983 - val_accuracy: 0.6883\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0593 - accuracy: 0.9840 - val_loss: 1.3080 - val_accuracy: 0.6962\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 1.2972 - val_accuracy: 0.6851\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 1.1833 - val_accuracy: 0.6883\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0360 - accuracy: 0.9903 - val_loss: 1.3239 - val_accuracy: 0.6804\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 1.3679 - val_accuracy: 0.6962\n",
            "50/50 [==============================] - 7s 50ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 42s 269ms/step - loss: 0.9236 - accuracy: 0.5487 - val_loss: 0.7728 - val_accuracy: 0.6440\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.5644 - accuracy: 0.7558 - val_loss: 0.7205 - val_accuracy: 0.6899\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2433 - accuracy: 0.9131 - val_loss: 0.9393 - val_accuracy: 0.7104\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1216 - accuracy: 0.9623 - val_loss: 1.0772 - val_accuracy: 0.7168\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0794 - accuracy: 0.9771 - val_loss: 1.2447 - val_accuracy: 0.7184\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 1.4981 - val_accuracy: 0.6835\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0636 - accuracy: 0.9808 - val_loss: 1.1714 - val_accuracy: 0.6851\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 1.4098 - val_accuracy: 0.6835\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0396 - accuracy: 0.9882 - val_loss: 1.4833 - val_accuracy: 0.6899\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 1.7500 - val_accuracy: 0.6788\n",
            "50/50 [==============================] - 7s 50ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 42s 269ms/step - loss: 0.9170 - accuracy: 0.5589 - val_loss: 0.7693 - val_accuracy: 0.6741\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.5126 - accuracy: 0.7938 - val_loss: 0.7517 - val_accuracy: 0.6962\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2139 - accuracy: 0.9289 - val_loss: 0.8547 - val_accuracy: 0.6867\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1122 - accuracy: 0.9667 - val_loss: 1.0670 - val_accuracy: 0.6835\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 1.4088 - val_accuracy: 0.6804\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 1.3616 - val_accuracy: 0.6630\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0411 - accuracy: 0.9894 - val_loss: 1.6896 - val_accuracy: 0.6772\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 1.8270 - val_accuracy: 0.6677\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 1.8727 - val_accuracy: 0.6725\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 1.7131 - val_accuracy: 0.6741\n",
            "50/50 [==============================] - 7s 51ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 53s 340ms/step - loss: 0.9210 - accuracy: 0.5446 - val_loss: 0.7848 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.5643 - accuracy: 0.7589 - val_loss: 0.6891 - val_accuracy: 0.7152\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.2470 - accuracy: 0.9111 - val_loss: 0.8649 - val_accuracy: 0.7168\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1331 - accuracy: 0.9581 - val_loss: 1.1363 - val_accuracy: 0.6804\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 13s 150ms/step - loss: 0.0897 - accuracy: 0.9738 - val_loss: 1.0895 - val_accuracy: 0.7089\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 13s 150ms/step - loss: 0.0741 - accuracy: 0.9771 - val_loss: 1.1916 - val_accuracy: 0.7104\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0561 - accuracy: 0.9847 - val_loss: 1.2930 - val_accuracy: 0.6994\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0648 - accuracy: 0.9813 - val_loss: 1.1867 - val_accuracy: 0.7184\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 1.2806 - val_accuracy: 0.7009\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 1.3353 - val_accuracy: 0.7104\n",
            "50/50 [==============================] - 8s 63ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 54s 342ms/step - loss: 0.9227 - accuracy: 0.5571 - val_loss: 0.7774 - val_accuracy: 0.6361\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.5442 - accuracy: 0.7742 - val_loss: 0.7125 - val_accuracy: 0.7041\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.2288 - accuracy: 0.9184 - val_loss: 0.9461 - val_accuracy: 0.6883\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1252 - accuracy: 0.9638 - val_loss: 1.1542 - val_accuracy: 0.7263\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 1.1812 - val_accuracy: 0.6962\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0651 - accuracy: 0.9826 - val_loss: 1.2522 - val_accuracy: 0.7294\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0579 - accuracy: 0.9840 - val_loss: 1.3563 - val_accuracy: 0.7073\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 1.5788 - val_accuracy: 0.7199\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 1.6211 - val_accuracy: 0.6962\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 1.4731 - val_accuracy: 0.6899\n",
            "50/50 [==============================] - 9s 65ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 371ms/step - loss: 0.9092 - accuracy: 0.5593 - val_loss: 0.7964 - val_accuracy: 0.6076\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.5606 - accuracy: 0.7625 - val_loss: 0.7158 - val_accuracy: 0.6915\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.2595 - accuracy: 0.9092 - val_loss: 0.9558 - val_accuracy: 0.6867\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.1323 - accuracy: 0.9576 - val_loss: 1.1838 - val_accuracy: 0.6930\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0914 - accuracy: 0.9736 - val_loss: 1.1388 - val_accuracy: 0.6741\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0588 - accuracy: 0.9838 - val_loss: 1.6226 - val_accuracy: 0.6582\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0550 - accuracy: 0.9838 - val_loss: 1.6227 - val_accuracy: 0.6566\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 1.5555 - val_accuracy: 0.6741\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.0443 - accuracy: 0.9887 - val_loss: 1.4637 - val_accuracy: 0.6661\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 1.6533 - val_accuracy: 0.6630\n",
            "50/50 [==============================] - 8s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 38s 270ms/step - loss: 0.9061 - accuracy: 0.5631 - val_loss: 0.6779 - val_accuracy: 0.7041\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.4430 - accuracy: 0.8216 - val_loss: 0.7155 - val_accuracy: 0.6994\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.2040 - accuracy: 0.9280 - val_loss: 0.9083 - val_accuracy: 0.7041\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.1084 - accuracy: 0.9650 - val_loss: 1.0363 - val_accuracy: 0.7025\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0749 - accuracy: 0.9745 - val_loss: 1.0889 - val_accuracy: 0.7104\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 1.3314 - val_accuracy: 0.7057\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0381 - accuracy: 0.9886 - val_loss: 1.2443 - val_accuracy: 0.7073\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 1.4894 - val_accuracy: 0.7057\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 1.5618 - val_accuracy: 0.6835\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 1.5716 - val_accuracy: 0.7057\n",
            "50/50 [==============================] - 6s 47ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 37s 268ms/step - loss: 0.9034 - accuracy: 0.5629 - val_loss: 0.6937 - val_accuracy: 0.6867\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.4512 - accuracy: 0.8137 - val_loss: 0.7660 - val_accuracy: 0.7358\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.1842 - accuracy: 0.9333 - val_loss: 0.9031 - val_accuracy: 0.7199\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0899 - accuracy: 0.9704 - val_loss: 1.0964 - val_accuracy: 0.6899\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 1.1767 - val_accuracy: 0.7104\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0526 - accuracy: 0.9852 - val_loss: 1.3198 - val_accuracy: 0.6867\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 1.3295 - val_accuracy: 0.6946\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 1.3762 - val_accuracy: 0.6978\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 1.6479 - val_accuracy: 0.6804\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 1.5685 - val_accuracy: 0.6820\n",
            "50/50 [==============================] - 6s 46ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 36s 252ms/step - loss: 0.9031 - accuracy: 0.5621 - val_loss: 0.7002 - val_accuracy: 0.6930\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 12s 134ms/step - loss: 0.4927 - accuracy: 0.8008 - val_loss: 0.7891 - val_accuracy: 0.6994\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 122ms/step - loss: 0.2125 - accuracy: 0.9307 - val_loss: 0.8859 - val_accuracy: 0.6994\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.1055 - accuracy: 0.9664 - val_loss: 1.1512 - val_accuracy: 0.6677\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.0778 - accuracy: 0.9762 - val_loss: 1.2807 - val_accuracy: 0.6804\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 1.5792 - val_accuracy: 0.6614\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0451 - accuracy: 0.9880 - val_loss: 1.4954 - val_accuracy: 0.6661\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 1.3888 - val_accuracy: 0.6598\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 1.5216 - val_accuracy: 0.6661\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 1.6049 - val_accuracy: 0.6725\n",
            "50/50 [==============================] - 6s 47ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 368ms/step - loss: 0.9067 - accuracy: 0.5531 - val_loss: 0.7187 - val_accuracy: 0.6582\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.4463 - accuracy: 0.8217 - val_loss: 0.6776 - val_accuracy: 0.7310\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.1970 - accuracy: 0.9324 - val_loss: 0.8334 - val_accuracy: 0.7326\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1165 - accuracy: 0.9608 - val_loss: 1.0187 - val_accuracy: 0.6994\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 1.1644 - val_accuracy: 0.7152\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.0519 - accuracy: 0.9828 - val_loss: 1.4738 - val_accuracy: 0.6930\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 1.2926 - val_accuracy: 0.7136\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 1.2771 - val_accuracy: 0.6978\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0396 - accuracy: 0.9882 - val_loss: 1.4306 - val_accuracy: 0.7104\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 1.4393 - val_accuracy: 0.6978\n",
            "50/50 [==============================] - 7s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 375ms/step - loss: 0.9263 - accuracy: 0.5587 - val_loss: 0.6882 - val_accuracy: 0.7168\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.4750 - accuracy: 0.8140 - val_loss: 0.6818 - val_accuracy: 0.7247\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1864 - accuracy: 0.9361 - val_loss: 0.9409 - val_accuracy: 0.6994\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1096 - accuracy: 0.9636 - val_loss: 0.9888 - val_accuracy: 0.6867\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0816 - accuracy: 0.9747 - val_loss: 1.2439 - val_accuracy: 0.6756\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 1.2559 - val_accuracy: 0.6883\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0491 - accuracy: 0.9866 - val_loss: 1.3618 - val_accuracy: 0.7041\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 1.5982 - val_accuracy: 0.6930\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.0288 - accuracy: 0.9919 - val_loss: 1.5663 - val_accuracy: 0.6709\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 1.5484 - val_accuracy: 0.6535\n",
            "50/50 [==============================] - 7s 63ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 53s 373ms/step - loss: 0.9018 - accuracy: 0.5716 - val_loss: 0.6911 - val_accuracy: 0.6946\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.4620 - accuracy: 0.8153 - val_loss: 0.7678 - val_accuracy: 0.6962\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.2103 - accuracy: 0.9305 - val_loss: 0.9510 - val_accuracy: 0.7025\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1099 - accuracy: 0.9666 - val_loss: 1.1241 - val_accuracy: 0.6994\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.0780 - accuracy: 0.9770 - val_loss: 1.2780 - val_accuracy: 0.6804\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.0538 - accuracy: 0.9845 - val_loss: 1.3687 - val_accuracy: 0.7041\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 0.0454 - accuracy: 0.9865 - val_loss: 1.6497 - val_accuracy: 0.6899\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0378 - accuracy: 0.9905 - val_loss: 1.4598 - val_accuracy: 0.6978\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0376 - accuracy: 0.9900 - val_loss: 1.6431 - val_accuracy: 0.6788\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 1.8848 - val_accuracy: 0.6646\n",
            "50/50 [==============================] - 7s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 69s 470ms/step - loss: 0.9150 - accuracy: 0.5515 - val_loss: 0.7749 - val_accuracy: 0.6266\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.6232 - accuracy: 0.7214 - val_loss: 0.7577 - val_accuracy: 0.6930\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.3000 - accuracy: 0.8890 - val_loss: 0.8496 - val_accuracy: 0.7041\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1458 - accuracy: 0.9534 - val_loss: 0.9963 - val_accuracy: 0.6851\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0953 - accuracy: 0.9720 - val_loss: 1.1495 - val_accuracy: 0.7152\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.0726 - accuracy: 0.9801 - val_loss: 1.1963 - val_accuracy: 0.6962\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0613 - accuracy: 0.9829 - val_loss: 1.2427 - val_accuracy: 0.6962\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 1.2127 - val_accuracy: 0.6962\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 1.3745 - val_accuracy: 0.7152\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0343 - accuracy: 0.9914 - val_loss: 1.4569 - val_accuracy: 0.6978\n",
            "50/50 [==============================] - 9s 82ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 67s 461ms/step - loss: 0.9131 - accuracy: 0.5575 - val_loss: 0.7913 - val_accuracy: 0.6408\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.5929 - accuracy: 0.7376 - val_loss: 0.7212 - val_accuracy: 0.6867\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.2783 - accuracy: 0.9064 - val_loss: 0.8702 - val_accuracy: 0.7089\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1687 - accuracy: 0.9432 - val_loss: 1.0562 - val_accuracy: 0.6804\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0922 - accuracy: 0.9720 - val_loss: 1.2628 - val_accuracy: 0.7136\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.0643 - accuracy: 0.9819 - val_loss: 1.4473 - val_accuracy: 0.6835\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0506 - accuracy: 0.9865 - val_loss: 1.3352 - val_accuracy: 0.6820\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 22s 246ms/step - loss: 0.0494 - accuracy: 0.9868 - val_loss: 1.4930 - val_accuracy: 0.6851\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0435 - accuracy: 0.9882 - val_loss: 1.5422 - val_accuracy: 0.6772\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 1.6517 - val_accuracy: 0.6851\n",
            "50/50 [==============================] - 9s 81ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 70s 478ms/step - loss: 0.9148 - accuracy: 0.5556 - val_loss: 0.8049 - val_accuracy: 0.5918\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.5756 - accuracy: 0.7447 - val_loss: 0.7513 - val_accuracy: 0.6867\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.2711 - accuracy: 0.9008 - val_loss: 0.8869 - val_accuracy: 0.6804\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1439 - accuracy: 0.9518 - val_loss: 1.0295 - val_accuracy: 0.6851\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0955 - accuracy: 0.9708 - val_loss: 1.1520 - val_accuracy: 0.6994\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0643 - accuracy: 0.9808 - val_loss: 1.3711 - val_accuracy: 0.6915\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0545 - accuracy: 0.9845 - val_loss: 1.5250 - val_accuracy: 0.6820\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.0662 - accuracy: 0.9806 - val_loss: 1.5277 - val_accuracy: 0.6661\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 1.4220 - val_accuracy: 0.6725\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 1.5458 - val_accuracy: 0.6772\n",
            "50/50 [==============================] - 9s 81ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 401ms/step - loss: 0.8841 - accuracy: 0.5759 - val_loss: 0.6961 - val_accuracy: 0.7073\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.4670 - accuracy: 0.8114 - val_loss: 0.7193 - val_accuracy: 0.6946\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.1997 - accuracy: 0.9280 - val_loss: 0.8647 - val_accuracy: 0.7263\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.1158 - accuracy: 0.9639 - val_loss: 0.9286 - val_accuracy: 0.7231\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0860 - accuracy: 0.9710 - val_loss: 1.0719 - val_accuracy: 0.7168\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 1.4356 - val_accuracy: 0.6915\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0628 - accuracy: 0.9789 - val_loss: 1.5147 - val_accuracy: 0.7136\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 1.4294 - val_accuracy: 0.6978\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0441 - accuracy: 0.9856 - val_loss: 1.5728 - val_accuracy: 0.6772\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0380 - accuracy: 0.9856 - val_loss: 1.6660 - val_accuracy: 0.6804\n",
            "50/50 [==============================] - 7s 69ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 54s 397ms/step - loss: 0.9022 - accuracy: 0.5626 - val_loss: 0.6845 - val_accuracy: 0.7057\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.4627 - accuracy: 0.8091 - val_loss: 0.7191 - val_accuracy: 0.7231\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 0.1863 - accuracy: 0.9308 - val_loss: 0.8670 - val_accuracy: 0.7089\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.1503 - accuracy: 0.9486 - val_loss: 1.1348 - val_accuracy: 0.7089\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 1.2254 - val_accuracy: 0.7120\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 1.4107 - val_accuracy: 0.7009\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0380 - accuracy: 0.9880 - val_loss: 1.5611 - val_accuracy: 0.6994\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 1.5697 - val_accuracy: 0.6930\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 1.6519 - val_accuracy: 0.6962\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 1.7233 - val_accuracy: 0.6820\n",
            "50/50 [==============================] - 7s 67ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 402ms/step - loss: 0.9125 - accuracy: 0.5660 - val_loss: 0.7268 - val_accuracy: 0.6693\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.4990 - accuracy: 0.7940 - val_loss: 0.7437 - val_accuracy: 0.7073\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.2101 - accuracy: 0.9235 - val_loss: 0.9571 - val_accuracy: 0.7009\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.1043 - accuracy: 0.9652 - val_loss: 1.2178 - val_accuracy: 0.6962\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0623 - accuracy: 0.9819 - val_loss: 1.3599 - val_accuracy: 0.6978\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 1.8328 - val_accuracy: 0.6187\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.2849 - accuracy: 0.9353 - val_loss: 1.4846 - val_accuracy: 0.6741\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0651 - accuracy: 0.9815 - val_loss: 1.4946 - val_accuracy: 0.6646\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 1.5934 - val_accuracy: 0.6867\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 1.7950 - val_accuracy: 0.6804\n",
            "50/50 [==============================] - 7s 67ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 85s 629ms/step - loss: 0.9179 - accuracy: 0.5428 - val_loss: 0.7747 - val_accuracy: 0.6282\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.5473 - accuracy: 0.7572 - val_loss: 0.6572 - val_accuracy: 0.7199\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.2802 - accuracy: 0.9013 - val_loss: 0.9304 - val_accuracy: 0.7247\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.1693 - accuracy: 0.9463 - val_loss: 1.0265 - val_accuracy: 0.7247\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.1107 - accuracy: 0.9669 - val_loss: 1.1107 - val_accuracy: 0.6994\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0771 - accuracy: 0.9789 - val_loss: 1.1947 - val_accuracy: 0.6915\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0522 - accuracy: 0.9857 - val_loss: 1.4693 - val_accuracy: 0.6930\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 1.5773 - val_accuracy: 0.6930\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 1.4369 - val_accuracy: 0.6535\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 1.3448 - val_accuracy: 0.6899\n",
            "50/50 [==============================] - 9s 99ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 84s 645ms/step - loss: 0.9247 - accuracy: 0.5506 - val_loss: 0.7156 - val_accuracy: 0.6835\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 34s 383ms/step - loss: 0.6328 - accuracy: 0.7475 - val_loss: 0.7929 - val_accuracy: 0.6772\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.2660 - accuracy: 0.9092 - val_loss: 0.8190 - val_accuracy: 0.7025\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 376ms/step - loss: 0.1796 - accuracy: 0.9470 - val_loss: 1.0078 - val_accuracy: 0.6994\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.1119 - accuracy: 0.9652 - val_loss: 1.0612 - val_accuracy: 0.7136\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0872 - accuracy: 0.9740 - val_loss: 1.2434 - val_accuracy: 0.6883\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 1.4046 - val_accuracy: 0.7089\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0478 - accuracy: 0.9861 - val_loss: 1.4221 - val_accuracy: 0.7136\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 1.5378 - val_accuracy: 0.6772\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 1.4769 - val_accuracy: 0.6962\n",
            "50/50 [==============================] - 9s 98ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 85s 636ms/step - loss: 0.9483 - accuracy: 0.5403 - val_loss: 0.7471 - val_accuracy: 0.6820\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.5221 - accuracy: 0.7833 - val_loss: 0.7239 - val_accuracy: 0.7199\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.2167 - accuracy: 0.9215 - val_loss: 0.9175 - val_accuracy: 0.7120\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.1120 - accuracy: 0.9587 - val_loss: 1.0773 - val_accuracy: 0.7041\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0898 - accuracy: 0.9710 - val_loss: 1.3305 - val_accuracy: 0.6867\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 1.2245 - val_accuracy: 0.6930\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0580 - accuracy: 0.9835 - val_loss: 1.4596 - val_accuracy: 0.6930\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 1.5210 - val_accuracy: 0.6804\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 1.5867 - val_accuracy: 0.6835\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 1.9280 - val_accuracy: 0.6677\n",
            "50/50 [==============================] - 9s 99ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 112s 860ms/step - loss: 0.9825 - accuracy: 0.5342 - val_loss: 0.7921 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.5303 - accuracy: 0.7800 - val_loss: 0.7137 - val_accuracy: 0.7231\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.2506 - accuracy: 0.9108 - val_loss: 0.8187 - val_accuracy: 0.7247\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1412 - accuracy: 0.9535 - val_loss: 0.9794 - val_accuracy: 0.7168\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0969 - accuracy: 0.9699 - val_loss: 1.2351 - val_accuracy: 0.7073\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0762 - accuracy: 0.9771 - val_loss: 1.3318 - val_accuracy: 0.7009\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 1.3127 - val_accuracy: 0.6851\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0539 - accuracy: 0.9843 - val_loss: 1.5875 - val_accuracy: 0.6741\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 1.5081 - val_accuracy: 0.6883\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 1.2836 - val_accuracy: 0.7073\n",
            "50/50 [==============================] - 12s 128ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 115s 910ms/step - loss: 0.9312 - accuracy: 0.5478 - val_loss: 0.8131 - val_accuracy: 0.6313\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.5857 - accuracy: 0.7394 - val_loss: 0.6775 - val_accuracy: 0.7294\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.2479 - accuracy: 0.9113 - val_loss: 0.9137 - val_accuracy: 0.7199\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1350 - accuracy: 0.9565 - val_loss: 0.9866 - val_accuracy: 0.7120\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1052 - accuracy: 0.9664 - val_loss: 1.1219 - val_accuracy: 0.6994\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0805 - accuracy: 0.9755 - val_loss: 1.1827 - val_accuracy: 0.7136\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0686 - accuracy: 0.9773 - val_loss: 1.2583 - val_accuracy: 0.6820\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 1.3680 - val_accuracy: 0.7089\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0490 - accuracy: 0.9859 - val_loss: 1.4273 - val_accuracy: 0.6994\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.8868 - accuracy: 0.5979 - val_loss: 1.0324 - val_accuracy: 0.5111\n",
            "50/50 [==============================] - 12s 127ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 113s 857ms/step - loss: 0.9152 - accuracy: 0.5479 - val_loss: 0.8273 - val_accuracy: 0.6092\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.5451 - accuracy: 0.7709 - val_loss: 0.7880 - val_accuracy: 0.6915\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.3283 - accuracy: 0.8865 - val_loss: 1.0839 - val_accuracy: 0.6456\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.2396 - accuracy: 0.9200 - val_loss: 1.0724 - val_accuracy: 0.6851\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1261 - accuracy: 0.9646 - val_loss: 1.2329 - val_accuracy: 0.6519\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0789 - accuracy: 0.9773 - val_loss: 1.4794 - val_accuracy: 0.6693\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0578 - accuracy: 0.9861 - val_loss: 1.4715 - val_accuracy: 0.6709\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0559 - accuracy: 0.9847 - val_loss: 1.4426 - val_accuracy: 0.6804\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0499 - accuracy: 0.9889 - val_loss: 1.5598 - val_accuracy: 0.6630\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.0486 - accuracy: 0.9877 - val_loss: 1.5497 - val_accuracy: 0.6820\n",
            "50/50 [==============================] - 12s 129ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 30s 200ms/step - loss: 1.0528 - accuracy: 0.4718 - val_loss: 1.0191 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 1.0227 - accuracy: 0.4874 - val_loss: 0.9760 - val_accuracy: 0.5427\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.8623 - accuracy: 0.5914 - val_loss: 0.8005 - val_accuracy: 0.6218\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.6954 - accuracy: 0.6667 - val_loss: 0.7970 - val_accuracy: 0.6282\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.5759 - accuracy: 0.7334 - val_loss: 0.8176 - val_accuracy: 0.6329\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.4509 - accuracy: 0.8124 - val_loss: 0.8585 - val_accuracy: 0.6424\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.3331 - accuracy: 0.8810 - val_loss: 1.0036 - val_accuracy: 0.6440\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.2405 - accuracy: 0.9217 - val_loss: 1.0504 - val_accuracy: 0.6377\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1882 - accuracy: 0.9381 - val_loss: 0.9802 - val_accuracy: 0.6851\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1350 - accuracy: 0.9579 - val_loss: 1.0968 - val_accuracy: 0.6851\n",
            "50/50 [==============================] - 6s 40ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 29s 196ms/step - loss: 1.0518 - accuracy: 0.4839 - val_loss: 1.0244 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 1.0256 - accuracy: 0.4897 - val_loss: 0.9948 - val_accuracy: 0.5301\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.9023 - accuracy: 0.5705 - val_loss: 0.7844 - val_accuracy: 0.6218\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.7236 - accuracy: 0.6567 - val_loss: 0.8257 - val_accuracy: 0.6297\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.6596 - accuracy: 0.6940 - val_loss: 0.7786 - val_accuracy: 0.6361\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.5428 - accuracy: 0.7487 - val_loss: 0.7705 - val_accuracy: 0.6661\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.4145 - accuracy: 0.8286 - val_loss: 0.8257 - val_accuracy: 0.7009\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.2902 - accuracy: 0.8942 - val_loss: 0.9190 - val_accuracy: 0.6915\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1864 - accuracy: 0.9365 - val_loss: 1.0499 - val_accuracy: 0.6788\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1278 - accuracy: 0.9594 - val_loss: 1.2166 - val_accuracy: 0.6772\n",
            "50/50 [==============================] - 7s 40ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 29s 195ms/step - loss: 1.0480 - accuracy: 0.4870 - val_loss: 1.0561 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 1.0252 - accuracy: 0.4914 - val_loss: 1.0180 - val_accuracy: 0.4826\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.8859 - accuracy: 0.5820 - val_loss: 0.8100 - val_accuracy: 0.5949\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.6865 - accuracy: 0.6835 - val_loss: 0.8050 - val_accuracy: 0.6203\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.5504 - accuracy: 0.7628 - val_loss: 0.8358 - val_accuracy: 0.6282\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.4146 - accuracy: 0.8427 - val_loss: 0.9566 - val_accuracy: 0.6250\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.2928 - accuracy: 0.9046 - val_loss: 1.0186 - val_accuracy: 0.6487\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.2144 - accuracy: 0.9374 - val_loss: 1.1294 - val_accuracy: 0.6408\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1698 - accuracy: 0.9516 - val_loss: 1.2625 - val_accuracy: 0.6519\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1448 - accuracy: 0.9616 - val_loss: 1.1967 - val_accuracy: 0.6582\n",
            "50/50 [==============================] - 7s 40ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 41s 271ms/step - loss: 1.0554 - accuracy: 0.4751 - val_loss: 1.0194 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 1.0142 - accuracy: 0.4987 - val_loss: 0.9264 - val_accuracy: 0.5854\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.7920 - accuracy: 0.6203 - val_loss: 0.7615 - val_accuracy: 0.6456\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.6478 - accuracy: 0.6819 - val_loss: 0.7642 - val_accuracy: 0.6218\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.5229 - accuracy: 0.7537 - val_loss: 0.8525 - val_accuracy: 0.6345\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 12s 134ms/step - loss: 0.4111 - accuracy: 0.8286 - val_loss: 0.9435 - val_accuracy: 0.6266\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.3122 - accuracy: 0.8840 - val_loss: 1.0649 - val_accuracy: 0.6297\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.2333 - accuracy: 0.9226 - val_loss: 1.1420 - val_accuracy: 0.6424\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.1684 - accuracy: 0.9532 - val_loss: 1.1683 - val_accuracy: 0.6582\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1363 - accuracy: 0.9606 - val_loss: 1.1602 - val_accuracy: 0.6392\n",
            "50/50 [==============================] - 7s 52ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 43s 296ms/step - loss: 1.0511 - accuracy: 0.4821 - val_loss: 1.0226 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 1.0203 - accuracy: 0.4962 - val_loss: 0.9507 - val_accuracy: 0.5459\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.8096 - accuracy: 0.6210 - val_loss: 0.7993 - val_accuracy: 0.6282\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.6643 - accuracy: 0.6848 - val_loss: 0.8038 - val_accuracy: 0.6377\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.5504 - accuracy: 0.7209 - val_loss: 0.8460 - val_accuracy: 0.6456\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 0.4452 - accuracy: 0.7948 - val_loss: 0.9740 - val_accuracy: 0.6203\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.3269 - accuracy: 0.8742 - val_loss: 1.1055 - val_accuracy: 0.6218\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 118ms/step - loss: 0.2408 - accuracy: 0.9173 - val_loss: 1.1125 - val_accuracy: 0.6282\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1489 - accuracy: 0.9527 - val_loss: 1.2851 - val_accuracy: 0.6598\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1025 - accuracy: 0.9701 - val_loss: 1.3491 - val_accuracy: 0.6519\n",
            "50/50 [==============================] - 7s 52ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 44s 273ms/step - loss: 1.0505 - accuracy: 0.4875 - val_loss: 1.0570 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 1.0172 - accuracy: 0.4984 - val_loss: 0.9665 - val_accuracy: 0.5364\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 0.8024 - accuracy: 0.6186 - val_loss: 0.8074 - val_accuracy: 0.6092\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.6577 - accuracy: 0.6807 - val_loss: 0.8184 - val_accuracy: 0.6060\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.5855 - accuracy: 0.7004 - val_loss: 0.8180 - val_accuracy: 0.6234\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.4536 - accuracy: 0.7915 - val_loss: 0.9182 - val_accuracy: 0.6408\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2889 - accuracy: 0.8913 - val_loss: 0.9511 - val_accuracy: 0.6930\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1814 - accuracy: 0.9430 - val_loss: 1.1283 - val_accuracy: 0.6788\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1349 - accuracy: 0.9578 - val_loss: 1.1224 - val_accuracy: 0.6756\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 10s 118ms/step - loss: 0.1030 - accuracy: 0.9687 - val_loss: 1.1851 - val_accuracy: 0.6915\n",
            "50/50 [==============================] - 7s 51ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 54s 344ms/step - loss: 1.0515 - accuracy: 0.4769 - val_loss: 1.0162 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.9800 - accuracy: 0.5207 - val_loss: 0.8207 - val_accuracy: 0.6187\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.7566 - accuracy: 0.6301 - val_loss: 0.7853 - val_accuracy: 0.6345\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.6369 - accuracy: 0.6829 - val_loss: 0.8170 - val_accuracy: 0.6282\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.5406 - accuracy: 0.7162 - val_loss: 0.8740 - val_accuracy: 0.6155\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 14s 158ms/step - loss: 0.4378 - accuracy: 0.7971 - val_loss: 0.9673 - val_accuracy: 0.6076\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.3267 - accuracy: 0.8781 - val_loss: 1.0690 - val_accuracy: 0.5949\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.2217 - accuracy: 0.9229 - val_loss: 1.2218 - val_accuracy: 0.6440\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1488 - accuracy: 0.9491 - val_loss: 1.1617 - val_accuracy: 0.6266\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1101 - accuracy: 0.9673 - val_loss: 1.3909 - val_accuracy: 0.6440\n",
            "50/50 [==============================] - 8s 65ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 56s 350ms/step - loss: 1.0527 - accuracy: 0.4853 - val_loss: 1.0280 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 1.0226 - accuracy: 0.4966 - val_loss: 0.9191 - val_accuracy: 0.5823\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.7891 - accuracy: 0.6278 - val_loss: 0.7781 - val_accuracy: 0.6329\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.6371 - accuracy: 0.6917 - val_loss: 0.8002 - val_accuracy: 0.6218\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.5138 - accuracy: 0.7679 - val_loss: 0.8708 - val_accuracy: 0.6218\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.3995 - accuracy: 0.8383 - val_loss: 0.9897 - val_accuracy: 0.6060\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.2864 - accuracy: 0.9013 - val_loss: 1.1169 - val_accuracy: 0.6155\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1934 - accuracy: 0.9396 - val_loss: 1.2263 - val_accuracy: 0.6408\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 0.1354 - accuracy: 0.9585 - val_loss: 1.3610 - val_accuracy: 0.6472\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.0994 - accuracy: 0.9715 - val_loss: 1.4659 - val_accuracy: 0.6472\n",
            "50/50 [==============================] - 9s 66ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 346ms/step - loss: 1.0487 - accuracy: 0.4865 - val_loss: 1.0556 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 13s 151ms/step - loss: 1.0003 - accuracy: 0.5144 - val_loss: 0.8684 - val_accuracy: 0.5617\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.7543 - accuracy: 0.6372 - val_loss: 0.8160 - val_accuracy: 0.6028\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.6391 - accuracy: 0.6874 - val_loss: 0.8318 - val_accuracy: 0.5997\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 14s 159ms/step - loss: 0.5373 - accuracy: 0.7194 - val_loss: 0.9647 - val_accuracy: 0.5934\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 13s 152ms/step - loss: 0.4354 - accuracy: 0.8061 - val_loss: 1.0334 - val_accuracy: 0.6123\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.3456 - accuracy: 0.8608 - val_loss: 1.1209 - val_accuracy: 0.6266\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.2639 - accuracy: 0.9115 - val_loss: 1.2184 - val_accuracy: 0.6266\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.2186 - accuracy: 0.9328 - val_loss: 1.3627 - val_accuracy: 0.6108\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 14s 152ms/step - loss: 0.1765 - accuracy: 0.9488 - val_loss: 1.4255 - val_accuracy: 0.6234\n",
            "50/50 [==============================] - 8s 67ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 36s 252ms/step - loss: 1.0529 - accuracy: 0.4747 - val_loss: 1.0259 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 1.0051 - accuracy: 0.5092 - val_loss: 0.8885 - val_accuracy: 0.5759\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.7899 - accuracy: 0.6219 - val_loss: 0.8116 - val_accuracy: 0.6250\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.6531 - accuracy: 0.6732 - val_loss: 0.7990 - val_accuracy: 0.6313\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.5365 - accuracy: 0.7406 - val_loss: 0.8644 - val_accuracy: 0.6361\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.4168 - accuracy: 0.8277 - val_loss: 0.9005 - val_accuracy: 0.6582\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.3051 - accuracy: 0.8842 - val_loss: 0.9133 - val_accuracy: 0.6614\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 12s 140ms/step - loss: 0.2214 - accuracy: 0.9213 - val_loss: 0.9405 - val_accuracy: 0.6630\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.1704 - accuracy: 0.9405 - val_loss: 0.9574 - val_accuracy: 0.6582\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.1272 - accuracy: 0.9599 - val_loss: 1.1241 - val_accuracy: 0.6440\n",
            "50/50 [==============================] - 6s 48ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 36s 248ms/step - loss: 1.0451 - accuracy: 0.4857 - val_loss: 1.0172 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.9858 - accuracy: 0.5247 - val_loss: 0.8394 - val_accuracy: 0.6076\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.7548 - accuracy: 0.6426 - val_loss: 0.7972 - val_accuracy: 0.6218\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.6330 - accuracy: 0.6936 - val_loss: 0.7968 - val_accuracy: 0.6519\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.5190 - accuracy: 0.7598 - val_loss: 0.8567 - val_accuracy: 0.6598\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.3527 - accuracy: 0.8557 - val_loss: 0.8471 - val_accuracy: 0.6899\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2139 - accuracy: 0.9250 - val_loss: 1.0282 - val_accuracy: 0.6883\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1463 - accuracy: 0.9511 - val_loss: 1.0819 - val_accuracy: 0.6693\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 12s 134ms/step - loss: 0.0865 - accuracy: 0.9752 - val_loss: 1.2459 - val_accuracy: 0.6772\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 11s 121ms/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 1.2869 - val_accuracy: 0.6646\n",
            "50/50 [==============================] - 6s 47ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 36s 249ms/step - loss: 1.0452 - accuracy: 0.4859 - val_loss: 1.0515 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.9654 - accuracy: 0.5273 - val_loss: 0.8672 - val_accuracy: 0.5712\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.7477 - accuracy: 0.6351 - val_loss: 0.8342 - val_accuracy: 0.6028\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.6404 - accuracy: 0.6828 - val_loss: 0.8538 - val_accuracy: 0.5886\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.6009 - accuracy: 0.7041 - val_loss: 0.8639 - val_accuracy: 0.5854\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 11s 120ms/step - loss: 0.5350 - accuracy: 0.7458 - val_loss: 0.8851 - val_accuracy: 0.6313\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.3886 - accuracy: 0.8304 - val_loss: 0.9421 - val_accuracy: 0.6978\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.2691 - accuracy: 0.8967 - val_loss: 0.9419 - val_accuracy: 0.7057\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 11s 119ms/step - loss: 0.1961 - accuracy: 0.9256 - val_loss: 1.0419 - val_accuracy: 0.7025\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 12s 136ms/step - loss: 0.1338 - accuracy: 0.9551 - val_loss: 1.3703 - val_accuracy: 0.6598\n",
            "50/50 [==============================] - 6s 47ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 398ms/step - loss: 1.0490 - accuracy: 0.4753 - val_loss: 1.0205 - val_accuracy: 0.5158\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.9351 - accuracy: 0.5585 - val_loss: 0.8205 - val_accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 182ms/step - loss: 0.7067 - accuracy: 0.6570 - val_loss: 0.7818 - val_accuracy: 0.6392\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.5728 - accuracy: 0.7193 - val_loss: 0.8429 - val_accuracy: 0.6361\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.4410 - accuracy: 0.7989 - val_loss: 0.9416 - val_accuracy: 0.5981\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.3260 - accuracy: 0.8670 - val_loss: 0.9666 - val_accuracy: 0.6630\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.2048 - accuracy: 0.9293 - val_loss: 1.2243 - val_accuracy: 0.6155\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1622 - accuracy: 0.9481 - val_loss: 1.2560 - val_accuracy: 0.6772\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 0.1083 - accuracy: 0.9685 - val_loss: 1.3977 - val_accuracy: 0.6472\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0816 - accuracy: 0.9754 - val_loss: 1.2927 - val_accuracy: 0.6661\n",
            "50/50 [==============================] - 8s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 57s 383ms/step - loss: 1.0451 - accuracy: 0.4862 - val_loss: 1.0224 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.9324 - accuracy: 0.5596 - val_loss: 0.8229 - val_accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.7249 - accuracy: 0.6518 - val_loss: 0.7784 - val_accuracy: 0.6361\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.6042 - accuracy: 0.7007 - val_loss: 0.8300 - val_accuracy: 0.6187\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.4835 - accuracy: 0.7632 - val_loss: 0.9680 - val_accuracy: 0.6108\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.3342 - accuracy: 0.8564 - val_loss: 1.0947 - val_accuracy: 0.6709\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1930 - accuracy: 0.9298 - val_loss: 1.3211 - val_accuracy: 0.6472\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1325 - accuracy: 0.9551 - val_loss: 1.4556 - val_accuracy: 0.6646\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0896 - accuracy: 0.9718 - val_loss: 1.5812 - val_accuracy: 0.6566\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0636 - accuracy: 0.9803 - val_loss: 1.6728 - val_accuracy: 0.6519\n",
            "50/50 [==============================] - 8s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 371ms/step - loss: 1.0423 - accuracy: 0.4842 - val_loss: 1.0438 - val_accuracy: 0.4557\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.9029 - accuracy: 0.5704 - val_loss: 0.8296 - val_accuracy: 0.5997\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.6946 - accuracy: 0.6677 - val_loss: 0.8325 - val_accuracy: 0.5949\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 0.5723 - accuracy: 0.7109 - val_loss: 0.8558 - val_accuracy: 0.5949\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.4616 - accuracy: 0.7908 - val_loss: 0.9221 - val_accuracy: 0.6250\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.3228 - accuracy: 0.8691 - val_loss: 1.0082 - val_accuracy: 0.6962\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1938 - accuracy: 0.9317 - val_loss: 1.1557 - val_accuracy: 0.6788\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1322 - accuracy: 0.9581 - val_loss: 1.1029 - val_accuracy: 0.6756\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.1047 - accuracy: 0.9685 - val_loss: 1.2918 - val_accuracy: 0.6899\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 16s 180ms/step - loss: 0.0769 - accuracy: 0.9771 - val_loss: 1.5030 - val_accuracy: 0.6677\n",
            "50/50 [==============================] - 7s 64ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 67s 474ms/step - loss: 1.0484 - accuracy: 0.4760 - val_loss: 1.0121 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.9100 - accuracy: 0.5590 - val_loss: 0.7970 - val_accuracy: 0.6345\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.6998 - accuracy: 0.6565 - val_loss: 0.7870 - val_accuracy: 0.6329\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.5667 - accuracy: 0.7230 - val_loss: 0.8229 - val_accuracy: 0.6345\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.4489 - accuracy: 0.8071 - val_loss: 0.9097 - val_accuracy: 0.6250\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.3292 - accuracy: 0.8712 - val_loss: 1.0216 - val_accuracy: 0.6472\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.2150 - accuracy: 0.9196 - val_loss: 1.1854 - val_accuracy: 0.6424\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1584 - accuracy: 0.9462 - val_loss: 1.2074 - val_accuracy: 0.6725\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1049 - accuracy: 0.9664 - val_loss: 1.1964 - val_accuracy: 0.6535\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 237ms/step - loss: 0.0770 - accuracy: 0.9778 - val_loss: 1.3150 - val_accuracy: 0.6820\n",
            "50/50 [==============================] - 9s 82ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 69s 475ms/step - loss: 1.0488 - accuracy: 0.4850 - val_loss: 1.0199 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.9406 - accuracy: 0.5504 - val_loss: 0.8008 - val_accuracy: 0.6424\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.7174 - accuracy: 0.6532 - val_loss: 0.8011 - val_accuracy: 0.6250\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.5870 - accuracy: 0.7031 - val_loss: 0.8659 - val_accuracy: 0.6108\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.4821 - accuracy: 0.7660 - val_loss: 0.9938 - val_accuracy: 0.6266\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.3487 - accuracy: 0.8585 - val_loss: 1.0051 - val_accuracy: 0.6329\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.2087 - accuracy: 0.9252 - val_loss: 1.2394 - val_accuracy: 0.6424\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.1367 - accuracy: 0.9572 - val_loss: 1.2887 - val_accuracy: 0.6630\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0985 - accuracy: 0.9690 - val_loss: 1.4032 - val_accuracy: 0.6535\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0684 - accuracy: 0.9773 - val_loss: 1.6575 - val_accuracy: 0.6456\n",
            "50/50 [==============================] - 10s 82ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 68s 490ms/step - loss: 1.0476 - accuracy: 0.4842 - val_loss: 1.0573 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.9252 - accuracy: 0.5537 - val_loss: 0.8299 - val_accuracy: 0.5997\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 0.7061 - accuracy: 0.6559 - val_loss: 0.8323 - val_accuracy: 0.6013\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.5766 - accuracy: 0.7145 - val_loss: 0.8254 - val_accuracy: 0.6361\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.4424 - accuracy: 0.8033 - val_loss: 0.8990 - val_accuracy: 0.6551\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.3216 - accuracy: 0.8763 - val_loss: 1.0491 - val_accuracy: 0.6424\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.2017 - accuracy: 0.9321 - val_loss: 1.2142 - val_accuracy: 0.6741\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.1306 - accuracy: 0.9594 - val_loss: 1.3452 - val_accuracy: 0.6614\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0908 - accuracy: 0.9747 - val_loss: 1.3971 - val_accuracy: 0.6693\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 0.0776 - accuracy: 0.9748 - val_loss: 1.5395 - val_accuracy: 0.6551\n",
            "50/50 [==============================] - 10s 82ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 55s 423ms/step - loss: 1.0413 - accuracy: 0.4776 - val_loss: 0.9949 - val_accuracy: 0.5348\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.8998 - accuracy: 0.5701 - val_loss: 0.8059 - val_accuracy: 0.6297\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.7085 - accuracy: 0.6511 - val_loss: 0.7770 - val_accuracy: 0.6345\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.5592 - accuracy: 0.7387 - val_loss: 0.7897 - val_accuracy: 0.6630\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.4034 - accuracy: 0.8339 - val_loss: 0.8459 - val_accuracy: 0.6709\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.2459 - accuracy: 0.9062 - val_loss: 0.9447 - val_accuracy: 0.6788\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.1528 - accuracy: 0.9465 - val_loss: 0.9558 - val_accuracy: 0.6835\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.1289 - accuracy: 0.9569 - val_loss: 1.2075 - val_accuracy: 0.6725\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 1.3336 - val_accuracy: 0.6741\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0646 - accuracy: 0.9777 - val_loss: 1.4161 - val_accuracy: 0.6883\n",
            "50/50 [==============================] - 7s 67ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 52s 398ms/step - loss: 1.0434 - accuracy: 0.4874 - val_loss: 1.0105 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 22s 245ms/step - loss: 0.9072 - accuracy: 0.5699 - val_loss: 0.8193 - val_accuracy: 0.6218\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 0.7043 - accuracy: 0.6625 - val_loss: 0.8024 - val_accuracy: 0.6313\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 0.5817 - accuracy: 0.7222 - val_loss: 0.8705 - val_accuracy: 0.6377\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.4252 - accuracy: 0.8170 - val_loss: 0.9532 - val_accuracy: 0.6630\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.2671 - accuracy: 0.8986 - val_loss: 1.0193 - val_accuracy: 0.6725\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.1588 - accuracy: 0.9433 - val_loss: 1.1809 - val_accuracy: 0.6772\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.1170 - accuracy: 0.9615 - val_loss: 1.4107 - val_accuracy: 0.6582\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0856 - accuracy: 0.9727 - val_loss: 1.5717 - val_accuracy: 0.6646\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 1.7024 - val_accuracy: 0.6487\n",
            "50/50 [==============================] - 7s 68ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 53s 410ms/step - loss: 1.0418 - accuracy: 0.4863 - val_loss: 1.0439 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 0.9305 - accuracy: 0.5508 - val_loss: 0.8424 - val_accuracy: 0.5918\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 22s 246ms/step - loss: 0.7094 - accuracy: 0.6546 - val_loss: 0.7968 - val_accuracy: 0.5997\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.5542 - accuracy: 0.7373 - val_loss: 0.7703 - val_accuracy: 0.6788\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.3614 - accuracy: 0.8561 - val_loss: 0.8905 - val_accuracy: 0.6835\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.2072 - accuracy: 0.9235 - val_loss: 1.0185 - val_accuracy: 0.6772\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.6840 - accuracy: 0.8966 - val_loss: 1.0814 - val_accuracy: 0.6566\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 0.1079 - accuracy: 0.9666 - val_loss: 1.2602 - val_accuracy: 0.6503\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0841 - accuracy: 0.9733 - val_loss: 1.4045 - val_accuracy: 0.6535\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 1.3528 - val_accuracy: 0.6646\n",
            "50/50 [==============================] - 7s 66ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 87s 657ms/step - loss: 1.0435 - accuracy: 0.4825 - val_loss: 1.0161 - val_accuracy: 0.5411\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.8429 - accuracy: 0.5974 - val_loss: 0.8025 - val_accuracy: 0.6218\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.6762 - accuracy: 0.6722 - val_loss: 0.8170 - val_accuracy: 0.6218\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.5560 - accuracy: 0.7172 - val_loss: 0.8588 - val_accuracy: 0.6566\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.3901 - accuracy: 0.8279 - val_loss: 1.0389 - val_accuracy: 0.6820\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.2276 - accuracy: 0.9127 - val_loss: 0.9873 - val_accuracy: 0.6630\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.1399 - accuracy: 0.9541 - val_loss: 1.1908 - val_accuracy: 0.6424\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0923 - accuracy: 0.9741 - val_loss: 1.2696 - val_accuracy: 0.6598\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0924 - accuracy: 0.9699 - val_loss: 1.3153 - val_accuracy: 0.6820\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0598 - accuracy: 0.9821 - val_loss: 1.5540 - val_accuracy: 0.6345\n",
            "50/50 [==============================] - 9s 98ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 85s 637ms/step - loss: 1.0442 - accuracy: 0.4820 - val_loss: 1.0015 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.8539 - accuracy: 0.5979 - val_loss: 0.8153 - val_accuracy: 0.6297\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.6591 - accuracy: 0.6768 - val_loss: 0.8100 - val_accuracy: 0.6503\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.4783 - accuracy: 0.7867 - val_loss: 0.8126 - val_accuracy: 0.6661\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.2779 - accuracy: 0.8951 - val_loss: 1.0133 - val_accuracy: 0.6677\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.1713 - accuracy: 0.9411 - val_loss: 1.1183 - val_accuracy: 0.6677\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.1012 - accuracy: 0.9669 - val_loss: 1.4473 - val_accuracy: 0.6899\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0863 - accuracy: 0.9740 - val_loss: 1.5694 - val_accuracy: 0.6646\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 1.4959 - val_accuracy: 0.6661\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0521 - accuracy: 0.9865 - val_loss: 1.7122 - val_accuracy: 0.6677\n",
            "50/50 [==============================] - 9s 99ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 85s 634ms/step - loss: 1.0409 - accuracy: 0.4886 - val_loss: 1.0453 - val_accuracy: 0.4525\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.8662 - accuracy: 0.5843 - val_loss: 0.8184 - val_accuracy: 0.5981\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.6723 - accuracy: 0.6712 - val_loss: 0.7839 - val_accuracy: 0.5981\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.5275 - accuracy: 0.7500 - val_loss: 0.8382 - val_accuracy: 0.6646\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.3346 - accuracy: 0.8637 - val_loss: 0.8926 - val_accuracy: 0.6978\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.1969 - accuracy: 0.9296 - val_loss: 1.0426 - val_accuracy: 0.6962\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.1232 - accuracy: 0.9565 - val_loss: 1.0262 - val_accuracy: 0.6978\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0880 - accuracy: 0.9740 - val_loss: 1.5042 - val_accuracy: 0.6725\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 0.0705 - accuracy: 0.9805 - val_loss: 1.2794 - val_accuracy: 0.7025\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 1.4342 - val_accuracy: 0.6741\n",
            "50/50 [==============================] - 10s 97ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 114s 892ms/step - loss: 1.0459 - accuracy: 0.4816 - val_loss: 0.9831 - val_accuracy: 0.5396\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.8492 - accuracy: 0.5902 - val_loss: 0.7982 - val_accuracy: 0.6171\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.6773 - accuracy: 0.6641 - val_loss: 0.8013 - val_accuracy: 0.6139\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.5506 - accuracy: 0.7302 - val_loss: 0.8866 - val_accuracy: 0.6171\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.9789 - val_accuracy: 0.6392\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.2706 - accuracy: 0.8942 - val_loss: 1.0995 - val_accuracy: 0.6044\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1688 - accuracy: 0.9407 - val_loss: 1.1385 - val_accuracy: 0.6519\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.1185 - accuracy: 0.9594 - val_loss: 1.3728 - val_accuracy: 0.6424\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0792 - accuracy: 0.9759 - val_loss: 1.3686 - val_accuracy: 0.6456\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 1.4834 - val_accuracy: 0.6424\n",
            "50/50 [==============================] - 12s 129ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 115s 867ms/step - loss: 1.0392 - accuracy: 0.4894 - val_loss: 0.9966 - val_accuracy: 0.5427\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.8332 - accuracy: 0.6062 - val_loss: 0.7990 - val_accuracy: 0.6313\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.6775 - accuracy: 0.6706 - val_loss: 0.8151 - val_accuracy: 0.6361\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 518ms/step - loss: 0.5741 - accuracy: 0.7058 - val_loss: 0.8647 - val_accuracy: 0.6187\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.4806 - accuracy: 0.7522 - val_loss: 1.0693 - val_accuracy: 0.6171\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.3487 - accuracy: 0.8483 - val_loss: 1.0716 - val_accuracy: 0.6282\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.2126 - accuracy: 0.9217 - val_loss: 1.2369 - val_accuracy: 0.6456\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1284 - accuracy: 0.9560 - val_loss: 1.5317 - val_accuracy: 0.6171\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0901 - accuracy: 0.9729 - val_loss: 1.5051 - val_accuracy: 0.6456\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0584 - accuracy: 0.9828 - val_loss: 1.6794 - val_accuracy: 0.6266\n",
            "50/50 [==============================] - 12s 128ms/step\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 114s 880ms/step - loss: 1.0380 - accuracy: 0.4917 - val_loss: 0.9727 - val_accuracy: 0.5190\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.8324 - accuracy: 0.6071 - val_loss: 0.8210 - val_accuracy: 0.5981\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.6722 - accuracy: 0.6687 - val_loss: 0.8719 - val_accuracy: 0.5997\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.5586 - accuracy: 0.7055 - val_loss: 0.9934 - val_accuracy: 0.5918\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.4544 - accuracy: 0.7840 - val_loss: 1.1435 - val_accuracy: 0.5870\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.3305 - accuracy: 0.8598 - val_loss: 1.1178 - val_accuracy: 0.6408\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.2078 - accuracy: 0.9196 - val_loss: 1.2742 - val_accuracy: 0.6361\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1293 - accuracy: 0.9536 - val_loss: 1.4399 - val_accuracy: 0.6139\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 1.6292 - val_accuracy: 0.6329\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.0673 - accuracy: 0.9773 - val_loss: 1.6603 - val_accuracy: 0.6408\n",
            "50/50 [==============================] - 12s 128ms/step\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 50s 222ms/step - loss: 0.8600 - accuracy: 0.5832 - val_loss: 0.6646 - val_accuracy: 0.7057\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.4528 - accuracy: 0.8185 - val_loss: 0.6849 - val_accuracy: 0.7479\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 16s 116ms/step - loss: 0.2155 - accuracy: 0.9257 - val_loss: 0.8789 - val_accuracy: 0.7226\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.1296 - accuracy: 0.9577 - val_loss: 1.0346 - val_accuracy: 0.6983\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.0826 - accuracy: 0.9738 - val_loss: 1.0879 - val_accuracy: 0.7162\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.0656 - accuracy: 0.9795 - val_loss: 1.2561 - val_accuracy: 0.6973\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 1.3881 - val_accuracy: 0.7089\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 16s 117ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 1.3885 - val_accuracy: 0.6973\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 16s 116ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 1.5405 - val_accuracy: 0.6983\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 16s 116ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 1.6001 - val_accuracy: 0.7141\n"
          ]
        }
      ],
      "source": [
        "with tpu_strategy.scope():\n",
        "  grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e23KiurDXC55",
        "outputId": "c803dbee-d0f8-4ab5-8164-bad910a09d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found:  {'rnn__learning_rate': 0.001, 'rnn__lstm_size': 128, 'rnn__num_layers': 2}\n",
            "Best cross-validation score: 0.54\n"
          ]
        }
      ],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usb3dmsrXC55"
      },
      "source": [
        "# Test Model\n",
        "Now it's time to test the best model combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "G_3CW3vVXC56"
      },
      "outputs": [],
      "source": [
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UcEmUpWXC56",
        "outputId": "4b90c912-8894-4b34-ad8c-80a220fe32ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 7s 63ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p2S6zmuXC56",
        "outputId": "37912657-990d-4702-e82f-ba5049a3ba8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 73.45%\n"
          ]
        }
      ],
      "source": [
        "best_accuracy = np.mean(predictions == np.argmax(y_test_oh, axis=1))\n",
        "print(f\"Test accuracy: {best_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQEG0R0ZXC56"
      },
      "source": [
        "# Conclusion\n",
        "In this project, I developed a Sentiment Analysis model using a Recurrent Neural Network (RNN) architecture implemented with TensorFlow and Keras. The goal was to classify the sentiment of text data into positive or negative categories. Here’s a summary of my approach and findings:\n",
        "\n",
        "1. **Results**: The best model achieved a test **accuracy of 73.45%**, which fell short of my expectations. This outcome may be attributed to over-processing the data and the dataset itself. Given that the original text sequences were not particularly long, each adjustment and preprocessing step reduced the amount of usable data, potentially compromising the model's performance and its ability to capture features. The data was heavily skewed towards positive and neutral sentiments, so having a more even exposure would give the model less bias from negative sentiment. I also believe that if I had more compute power, the pipeline would have produced a winning model (90% and above) between thet 5 hyperparameters.\n",
        "\n",
        "2. **Model Architecture**: RNN with LSTM layers are well-suited for sequential data like text due to their ability to capture dependencies over time. The model included embedding layers for text representation, multiple LSTM layers for learning hierarchical features, and dropout layers for regularization.\n",
        "\n",
        "3. **Hyperparameter Tuning**: I utilized GridSearchCV to systematically search through different combinations of hyperparameters such as sequence length (`seq_len`), LSTM size (`lstm_size`), number of layers (`num_layers`), batch size (`batch_size`), and learning rate (`learning_rate`).  The goal was to optimize model performance by finding the best configuration for these parameters. The best model had a `learning_rate` of 0.001, a `lstm_size` of 128, and `num_layers` of 2.\n",
        "\n",
        "4. **Training and Evaluation**: I evaluated the model’s performance using metrics like accuracy to measure its ability to correctly predict sentiment labels on unseen data.\n",
        "\n",
        "5. **Performance**: Through iterative tuning and evaluation, I observed improvements in the model’s accuracy as I optimized hyperparameters. This process allowed us to fine-tune the model to achieve better performance in sentiment classification tasks.\n",
        "\n",
        "6. **Challenges and Considerations**: During the project, I encountered challenges such as balancing model complexity with computational resources and managing overfitting. Regularization techniques like dropout and careful selection of hyperparameters were crucial in addressing these challenges. Maybe adding a batch normalizer would have enhanced the performance. \n",
        "\n",
        "7. **Future Directions**: Moving forward, further enhancements could include exploring more advanced RNN variants (e.g., GRU, bi-directional LSTM), incorporating pre-trained word embeddings (e.g., Word2Vec, GloVe), or leveraging transfer learning techniques from larger language models (e.g., BERT, GPT). Additionally, expanding the dataset size and diversity could help generalize the model’s ability to handle different types of sentiment analysis tasks and domains.\n",
        "\n",
        "In conclusion, this project demonstrated the effectiveness of RNN-based architectures for sentiment analysis tasks and highlighted the importance of hyperparameter tuning in optimizing model performance. By continually refining and expanding upon these techniques, I can advance the state-of-the-art in natural language processing applications, particularly in sentiment analysis and related domains."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
